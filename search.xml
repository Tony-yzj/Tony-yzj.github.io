<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>向量化加速:尝试基于SIMD加速最大子矩阵和问题</title>
      <link href="/2022/12/28/%E6%9C%80%E5%A4%A7%E5%AD%90%E7%9F%A9%E9%98%B5%E5%92%8C%E9%97%AE%E9%A2%98%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96%E5%8A%A0%E9%80%9F%E6%8E%A2%E7%A9%B6%E4%B8%8E%E6%89%A9%E5%B1%95/"/>
      <url>/2022/12/28/%E6%9C%80%E5%A4%A7%E5%AD%90%E7%9F%A9%E9%98%B5%E5%92%8C%E9%97%AE%E9%A2%98%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96%E5%8A%A0%E9%80%9F%E6%8E%A2%E7%A9%B6%E4%B8%8E%E6%89%A9%E5%B1%95/</url>
      
        <content type="html"><![CDATA[<h1 id="最大子矩阵和问题的向量化加速探究与扩展"><a href="#最大子矩阵和问题的向量化加速探究与扩展" class="headerlink" title="最大子矩阵和问题的向量化加速探究与扩展"></a><center><strong>最大子矩阵和问题的向量化加速探究与扩展</strong></h1><p>课程名称：汇编与接口</p><p>学生姓名：云中君</p><p>学号：********</p><p>邮件地址：********@zju.edu.cn</p><hr><h2 id="一、探索背景"><a href="#一、探索背景" class="headerlink" title="一、探索背景"></a>一、探索背景</h2><p>​在探索实验开始前，我回顾了过去自己写的很多工程，以从中选择合适的代码进行优化。我尝试着优化了数据库课程中实现的MiniSql和其他课程一些大程，但是发现对于这些大型工程，涉及的代码过于繁杂，且不可避免地使用了很多递归函数，我思索了很久也没有找到合适的加速方法，结果反而使得程序更慢。屡次碰壁的情况下，我发现自己在数据结构基础中，困难模式的程序中有一个是最大子矩阵和的问题，程序相对简洁，利于分析，也涉及到了矩阵相关的运算和循环，在代码结构上，十分契合本次探索的主题，故就该问题进行了向量化加速。</p><p>最大子矩阵和问题的具体描述如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最大子矩阵问题是基于《数据结构与算法分析》教程中“最大子序列和”问题的拓展，它要求我们将一维问题（序列）扩展为二维（矩阵）。更具体地说，我们需要设计 O(N^6)，O(N^4)以及更好的算法，以找到在给定的 N×N 矩阵中其所有元素之和为最大的子矩阵，并给出这个最大的和。</span><br></pre></td></tr></table></figure><p>​在程序设计上，我完成了O(N^6)，O(N^4)以及更优的在线算法，由于O(N^4)和在线算法结构相对类似，所有这里我对前两个复杂度的算法进行了优化。</p><hr><h2 id="二、探索过程"><a href="#二、探索过程" class="headerlink" title="二、探索过程"></a>二、探索过程</h2><h3 id="1-intrinsics选择和文件构成"><a href="#1-intrinsics选择和文件构成" class="headerlink" title="1. intrinsics选择和文件构成"></a>1. intrinsics选择和文件构成</h3><p>​在本实验中，我调用的版本是向量指令是<code>AVX2</code>，具体来说，在程序中包含了头文件<code>#include &lt;immintrin.h&gt;</code>，使用对应的<code>intrinsics</code>来实现向量化加速。</p><p>​包含测试文件的目录结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">├── O4_Test.c<span class="comment">//包含了O(N^4)未优化和优化的算法代码</span></span><br><span class="line">├── O6_Test.c<span class="comment">//包含了O(N^6)未优化和优化的算法代码</span></span><br><span class="line">├── output<span class="comment">//Test_case_producer.c输出可以重定向到该文件</span></span><br><span class="line">├── readme.txt</span><br><span class="line">└── Test_case_producer.c<span class="comment">//产生N*N的随机的矩阵</span></span><br></pre></td></tr></table></figure><p>​在编译时，需要加入<code>-mavx2 -mfma</code>等flag，以支持对应的<code>intrinsics</code>。</p><hr><h3 id="2-O-N-6-算法优化"><a href="#2-O-N-6-算法优化" class="headerlink" title="2. O(N^6)算法优化"></a>2. O(N^6)算法优化</h3><h4 id="2-1-原始算法描述"><a href="#2-1-原始算法描述" class="headerlink" title="2.1 原始算法描述"></a>2.1 原始算法描述</h4><p>​该算法的思路是十分简单的循环求解，即对每一个矩阵都进行遍历求和，详细伪代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> maxsub-matrixsum1&#123;<span class="type">float</span> M[ ][ ]: the matrix, <span class="type">int</span> N: the size of the matrix&#125;</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">float</span> ThisSum, MaxSum := <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> i, j, k, l, m, n;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span> to N<span class="number">-1</span>&#123;</span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">0</span> to N<span class="number">-1</span>&#123;</span><br><span class="line">            <span class="keyword">for</span> k := i to N<span class="number">-1</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> l := j to N<span class="number">-1</span> &#123;</span><br><span class="line">                    <span class="comment">/*find the (i,j) position and (k,l) position*/</span></span><br><span class="line">                    ThisSum := <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">for</span> m := i to k &#123;</span><br><span class="line">                        <span class="keyword">for</span> n := j to l &#123;</span><br><span class="line">                        ThisSum += M[m][n];</span><br><span class="line">                    &#125;<span class="comment">/*add from (i,j) to (k,l) */</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> ThisSum &gt; MaxSum then MaxSum := ThisSum;</span><br><span class="line">                <span class="comment">/* update the MaxSum*/</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> MaxSum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-依赖关系分析和向量化尝试"><a href="#2-2-依赖关系分析和向量化尝试" class="headerlink" title="2.2 依赖关系分析和向量化尝试"></a>2.2 依赖关系分析和向量化尝试</h4><p>​正是由于6层循环的嵌套，使得整体程序的效率十分低，复杂度也高达O(N^6)。很自然地，我们可以尝试使用向量化的方式，来对该算法进行加速。</p><p>​首先我们分析代码的结构，在6层循环当中，我们从内而外看，先进行简化，可以看到其最核心的加法操作可以抽象为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt;= m; i++ )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= n; j++ )</span><br><span class="line">    &#123;</span><br><span class="line">        T = T + M[i][j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​分析其依赖关系，可以看到在循环内，大致有如下图的几种数据依赖：</p><img src="image-20221220233618978.png" alt="image-20221220233618978" style="zoom:50%;" /><p>​因为T(即暂时存当前操作矩阵和的遍量<code>ThisSum</code>)这一跨循环的共有变量存在，在执行过程中数据之间存在了很大的依赖性，其中也存在真实依赖(<code>RAW</code>)，使得向量化难以继续。</p><p>​但是由于T的最终目的是运算当前子矩阵的元素和，具体执行的手段其实可以变化，我们只需要在保证结果正确的前提下，尽可能实现向量化即可。我们可以通过重命名的技术，消除处理RAW之外的反相关和输出相关；对于真相关，我们完全可以分别计算上图中S1、S2语句中的T，只需要在最后将这两个值相加即可，即使未能消除的循环间的真相关，也不会影响程序执行。</p><p>​基于这一思路，我们可以利用向量化的方法，对内层循环的加法进行并行化。我们可以将原先的T分成8个32位<code>float</code>变量，构成一个256位的<code>sum</code>向量；而对于每一行，我们一次<code>load</code> 8个变量到<code>value</code>向量，分别让其与<code>sum</code>向量进行打包相加，从而使并行化成为可能。在最后，我们只需一次性将<code>sum</code>向量导出到数组中，并进行相加，即可得到当前子矩阵的和，这样就实现了简单的向量化并行，具体算法如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Matrix Add--O6_revise1</span></span><br><span class="line"><span class="type">float</span> ThisSum = <span class="number">0</span>;<span class="comment">//reinitialize the temporary sum</span></span><br><span class="line"><span class="type">float</span> Sum[<span class="number">8</span>]=&#123;<span class="number">0</span>,&#125;;</span><br><span class="line">__m256 value;</span><br><span class="line">__m256 sum = _mm256_set1_ps(<span class="number">0</span>);</span><br><span class="line">sum = _mm256_set1_ps(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span>( i = <span class="number">0</span>; i &lt;= r; i++ )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; ROUNDDOWN(c,<span class="number">8</span>); j+=<span class="number">8</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        value = _mm256_loadu_ps(&amp;M[i+sr][j+sc]);</span><br><span class="line">        sum = _mm256_add_ps(sum, value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(; j &lt;= c; j++)</span><br><span class="line">        ThisSum += M[i+sr][j+sc];</span><br><span class="line">&#125;<span class="comment">//add from (i,j) to (k,l) by separately incrementing m,n</span></span><br><span class="line">_mm256_storeu_ps(Sum, sum);</span><br><span class="line">ThisSum += Sum[<span class="number">0</span>]+Sum[<span class="number">1</span>]+Sum[<span class="number">2</span>]+Sum[<span class="number">3</span>]+Sum[<span class="number">4</span>]+Sum[<span class="number">5</span>]+Sum[<span class="number">6</span>]+Sum[<span class="number">7</span>];</span><br><span class="line"><span class="keyword">if</span>( ThisSum &gt; MaxSum )</span><br><span class="line">    MaxSum = ThisSum;<span class="comment">//updating the MaxSum if the current sum is larger</span></span><br></pre></td></tr></table></figure><p>​这样的优化仅仅在内层循环，但是性能优化也提升为原来的3倍多，我也尝试了进一步展开外层循环，以进一步地并行化。但是仔细分析，发现很难再减少跨loop导致的加法次数，而向量化指令由于操作数的有限，并不能很好的发挥作用，在处理外层循环时，使用多线程编程可能会是处理比较复杂操作的好的选择。不过展开后仍然发现速度有轻微的提升，并不明显，推测是展开后缓存等效率上，可能会在某些情况下有所优化，但是也无从验证。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//unrolling the loop, makes little change... </span></span><br><span class="line"><span class="keyword">for</span>( i= <span class="number">0</span>; i &lt; ROUNDDOWN(r,<span class="number">2</span>); i+=<span class="number">2</span> )</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; ROUNDDOWN(c,<span class="number">8</span>); j+=<span class="number">8</span> )</span><br><span class="line">&#123;</span><br><span class="line">value1 = _mm256_loadu_ps(&amp;M[i+sr][j+sc]);</span><br><span class="line">value2 = _mm256_loadu_ps(&amp;M[i+<span class="number">1</span>+sr][j+sc]);</span><br><span class="line">            </span><br><span class="line">sum = _mm256_add_ps(sum, _mm256_add_ps(value1, value2));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(; j &lt;= c; j++)</span><br><span class="line">&#123;</span><br><span class="line">ThisSum += M[i+sr][j+sc];</span><br><span class="line">ThisSum += M[i+<span class="number">1</span>+sr][j+sc];</span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="comment">//add from (i,j) to (k,l) by separately incrementing m,n</span></span><br></pre></td></tr></table></figure><hr><h3 id="3-O-N-4-算法优化"><a href="#3-O-N-4-算法优化" class="headerlink" title="3. O(N^4)算法优化"></a>3. O(N^4)算法优化</h3><p>​对于前面的O(N^6)的算法而言，由于循环有6层，而内部仅有一个加法操作，可向量化的空间并不多，而且算法时间复杂度过高，在这个情况下，优化算法比起向量化并行而言，效益是更高的。所有我进一步尝试，在优化算法后，是否也可以进行进一步的向量化加速。</p><h4 id="3-1-原始算法描述"><a href="#3-1-原始算法描述" class="headerlink" title="3.1 原始算法描述"></a>3.1 原始算法描述</h4><p>​下面是O(N^4)的算法，基本思路为将二维压缩到一维，对于矩阵确定的两行，我们可以获取这两行之间每一列的元素和，存储在数组T中，则T中任意的连续元素和，即为对应的一个子矩阵的元素和。在这个算法下，确定两行需要N^2；而每次更新T的数组需要N，并列地获得所有连续元素和需要N^2，所以总算法复杂度为O(N^4)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> maxsub-matrixsum1&#123;<span class="type">int</span> M[ ][ ]: the matrix, <span class="type">int</span> N: the size of the matrix&#125;</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> ThisSum, MaxSum := <span class="number">0</span>, T[N]; </span><br><span class="line">    <span class="comment">/* T[N]: the temporary space to store the sum from M[i][k] to M[j][k] */</span></span><br><span class="line"><span class="type">int</span> i, j, k, l;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line"><span class="keyword">for</span> j := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line">T[j] := <span class="number">0</span>;</span><br><span class="line">&#125;<span class="comment">/*reinitialize the T[N] corresponding to i*/</span></span><br><span class="line"><span class="keyword">for</span> j := i to N<span class="number">-1</span> &#123;</span><br><span class="line"><span class="keyword">for</span> k := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line">T[k] += M[j][k];</span><br><span class="line">&#125;<span class="comment">/*T[k] = M[i][k]+M[i+1][k]+...+M[j][k]*/</span></span><br><span class="line"><span class="keyword">for</span> k := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line">ThisSum := <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> l := k to N<span class="number">-1</span> &#123;</span><br><span class="line">ThisSum += T[l]; <span class="comment">/*similar to the sub-sequence problem*/</span></span><br><span class="line"><span class="keyword">if</span> ThisSum &gt; MaxSum then MaxSum := ThisSum;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> MaxSum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-2-向量化加速尝试"><a href="#3-2-向量化加速尝试" class="headerlink" title="3.2 向量化加速尝试"></a>3.2 向量化加速尝试</h4><p>​有了前面优化的实践后，我对向量化指令的熟悉程度和使用思路有了更熟练的掌握。与前面同样地，对于过多层嵌套的循环，我们也可以先抽取出内层的细节，来尝试进行向量化加速。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; N; k++ )<span class="comment">//Each time we only need to add the new row to the array T</span></span><br><span class="line">&#123;</span><br><span class="line">    T[k] += M[j][k];<span class="comment">//T[k] = M[i][k]+M[i+1][k]+...+M[j][k]</span></span><br><span class="line">&#125;<span class="comment">//O(N)</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; N; k++)</span><br><span class="line">&#123;</span><br><span class="line">ThisSum = <span class="number">0</span>;<span class="comment">//reinitialize ThisSum</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> l = k; l &lt; N; l++ )</span><br><span class="line">&#123;</span><br><span class="line">        ThisSum += T[l];</span><br><span class="line">        <span class="keyword">if</span>( ThisSum &gt; MaxSum )<span class="comment">//Find the max subsequence sum. </span></span><br><span class="line">            MaxSum = ThisSum;</span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="comment">//O(N^2)</span></span><br></pre></td></tr></table></figure><p>​首先，对于前面O(N)的更新过程，有了前面的基础，可以很快速地完成加速，实现8次相加的并行。此处T[k]之间也没有任何依赖，所有很自然地，只需要<code>load</code>完成后，并行地利用向量进行加法运算即可。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>( k = <span class="number">0</span>; k &lt; ROUNDDOWN(N,<span class="number">8</span>); k+=<span class="number">8</span> )</span><br><span class="line">&#123;</span><br><span class="line">    value1 = _mm256_loadu_ps(&amp;M[j][k]);</span><br><span class="line">    value2 = _mm256_loadu_ps(&amp;T[k]);</span><br><span class="line">    value2 = _mm256_add_ps(value1, value2);</span><br><span class="line">    _mm256_storeu_ps(&amp;T[k], value2);<span class="comment">//T[k] = M[i][k]+M[i+1][k]+...+M[j][k]</span></span><br><span class="line">&#125;<span class="comment">//O(N)</span></span><br><span class="line"><span class="keyword">for</span>(; k &lt; N; k++)</span><br><span class="line">    T[k] += M[j][k];</span><br></pre></td></tr></table></figure><p>​但是这一处的优化，反映在实际程序运行时间上，却是微不足道的。回顾此前算法课程对时间复杂度的分析，不难发现，这一算法费时间的主要部分其实是下面的O(N^2)二层循环部分，与这一部分相比，前面的O(N)部分时间其实可以忽略不计，所以优化了前面部分，才没有很明显的变化。</p><h4 id="3-3-条件判断的处理"><a href="#3-3-条件判断的处理" class="headerlink" title="3.3 条件判断的处理"></a>3.3 条件判断的处理</h4><p>​所以，对于全局的优化，需要重点关注对二层循环的优化。首先注意到，这是一个带条件的循环，每一次，我们需要比较<code>ThisSum</code>和<code>MaxSum</code>的值，来确定是否需要更新最大和。这一点很大程度上阻碍了我们直接使用指令进行向量化的尝试。</p><p>​为了解决条件判断的问题，我们可以尝试从几个思路进行考虑：</p><ol><li>按照上课提到的方法，修改我们程序表达，消除条件判断；</li><li>调整算法的实现，规避条件判断；</li></ol><p>​对于第一个思路，如果直接消除条件判断，我们不难想到的一种直观的方法是，把条件判断作为bool值这些形式，参与到具体的计算。对于此处的条件判断，我们可以尝试改写为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; N; k++)</span><br><span class="line">&#123;</span><br><span class="line">ThisSum = <span class="number">0</span>;<span class="comment">//reinitialize ThisSum</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> l = k; l &lt; N; l++ )</span><br><span class="line">&#123;</span><br><span class="line">        ThisSum += T[l];</span><br><span class="line">        <span class="type">int</span> b = ThisSum &gt; MaxSum;</span><br><span class="line">        MaxSum = ThisSum * b + MaxSum * (<span class="number">1</span>-b); <span class="comment">//1. involve multiply operation!</span></span><br><span class="line">        MaxSum = ThisSum &amp; b | MaxSum &amp; ~b; <span class="comment">//2. then b should be sign extended</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="comment">//O(N^2)</span></span><br></pre></td></tr></table></figure><p>​第一种形式是最自然地想法，但是注意到我们引入了乘法，而乘法运算，我们在体系结构、计算机组成课程中都了解过，需要较多的时钟周期来完成，显然为了这样简单的操作，是得不偿失的。所以我们选择第二种，即使用<code>bitwise</code>的与&#x2F;或操作来完成。</p><p>​但是在依赖关系上，循环内层中，<code>ThisSum</code>、b变量(暂时存储比较结果)存在真依赖，而b的真依赖在循环之间是无关的，每个<code>ThisSum</code>和<code>MaxSum</code>对应一个唯一的b值，不会影响具体的操作。但是对于<code>ThisSum</code>而言，有条件比较存在，这一跨循环的依赖是难以消除的。因为对于每一次<code>MaxSum</code>的更新，都唯一决定于这一层循环中<code>ThisSum</code>的值，也就是<code>ThisSum</code>的值具有<strong>“记录”</strong>意义，每次修改得到的都对应最终某个子矩阵的和。所以我们不能像之前的加速方法那样对<code>ThisSum</code>进行分道，来破坏循环间的依赖。</p><img src="image-20221221201513712.png" alt="image-20221221201513712" style="zoom: 50%;" /><p>​但是从对O(N^6)算法的加速的经验上看，我们是不是也可以人为地处理<code>MaxSum</code>这一值，来破坏这一依赖关系，也就是让每次<code>ThisSum</code>在循环间互不相关，不会存在累加的效果。这一处的修改让人摸不着头脑，试图通过-O3查看汇编指令，让编译器给一些提示，但是发现编译器在此处并不采用向量化，只是简单的循环操作，没有采用并行。对此我思考了很久，似乎必须对代码进行重构（类似于课上讲的调换顺序的方法）才可以解决这一优化的瓶颈。</p><h4 id="3-4-向量化遇到的瓶颈及尝试"><a href="#3-4-向量化遇到的瓶颈及尝试" class="headerlink" title="3.4 向量化遇到的瓶颈及尝试"></a>3.4 向量化遇到的瓶颈及尝试</h4><p>​对此我思考了两种方法，在不改变原有代码含义的基础上，通过算法的表述的改进，来试图实现优化。</p><h5 id="3-4-1-使用矩阵操作来解决依赖"><a href="#3-4-1-使用矩阵操作来解决依赖" class="headerlink" title="3.4.1 使用矩阵操作来解决依赖"></a>3.4.1 使用矩阵操作来解决依赖</h5><p>​展开循环，仔细分析<code>ThisSum</code>的所有可能值，我们可以发现它是由下面这些值构成：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">数字n：表示T[n]，以N=<span class="number">4</span>为例</span><br><span class="line"></span><br><span class="line">ThisSum:</span><br><span class="line"><span class="number">1</span> <span class="number">1</span>+<span class="number">2</span> <span class="number">1</span>+<span class="number">2</span>+<span class="number">3</span> <span class="number">1</span>+<span class="number">2</span>+<span class="number">3</span>+<span class="number">4</span></span><br><span class="line"><span class="number">2</span> <span class="number">2</span>+<span class="number">3</span> <span class="number">2</span>+<span class="number">3</span>+<span class="number">4</span></span><br><span class="line"><span class="number">3</span> <span class="number">3</span>+<span class="number">4</span> </span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><p>​我们可以看到，对于所有<code>ThisSum</code>的可能值，可以表示为一个矩阵，这个矩阵的所有元素的值的最大值，与<code>MaxSum</code>的值进行比较，即可获得最终的最大值。观察这个矩阵的特性，我们不难发现，它可以表示为：<br><img src="gs.png"/><br>​这样就包含了我们前面列举的所有<code>ThisSum</code>的情况，也就是我们只需要比较结果矩阵的元素获取最大值即可，也就打破原来存在的依赖。这是我最开始想到的解决方案，但是很明显这里引入了乘法，但是因为在最开始探索时看了很多快速矩阵乘法的优化方法，包括看到过一个论文的报道<a href="https://www.nature.com/articles/s41586-022-05172-4">Discovering faster matrix multiplication algorithms with reinforcement learning | Nature</a>，我盲目地估计了矩阵乘法的速度，参考资料实现了简单的优化后的矩阵乘法算法后，经过测试后，发现还是得不偿失的，这也提醒我在开始优化前，需要合理地评估代价。</p><p>​下面是参考<a href="https://www.leiphone.com/category/yanxishe/Puevv3ZWxn0heoEv.html">OpenBLAS项目与矩阵乘法优化</a>实现的矩阵乘法（使用GEMM优化），主要的逻辑也就是在大矩阵进行乘法时，进行8*8的分块，每次对这一分块进行并行的乘法运算，以加速矩阵乘法，但是结果比优化前慢，说明引入乘法是很不明智的，也是我探索过程中踩过的一个坑。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//8x8 multiplication with AVX2 speeding up(element of the whole mult with GEMM)</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Mult_8x8</span><span class="params">(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C)</span> &#123;</span><br><span class="line">__m256 o[<span class="number">8</span>], a[<span class="number">8</span>], b;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i =<span class="number">0</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">o[i] = _mm256_setzero_ps();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">float</span> *B_row = B;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; r; i++) &#123;</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>] = _mm256_set1_ps(A[i]);</span><br><span class="line">a[<span class="number">1</span>] = _mm256_set1_ps(A[c+i]);</span><br><span class="line">a[<span class="number">2</span>] = _mm256_set1_ps(A[<span class="number">2</span>*c+i]);</span><br><span class="line">a[<span class="number">3</span>] = _mm256_set1_ps(A[<span class="number">3</span>*c+i]);</span><br><span class="line">a[<span class="number">4</span>] = _mm256_set1_ps(A[<span class="number">4</span>*c+i]);</span><br><span class="line">a[<span class="number">5</span>] = _mm256_set1_ps(A[<span class="number">5</span>*c+i]);</span><br><span class="line">a[<span class="number">6</span>] = _mm256_set1_ps(A[<span class="number">6</span>*c+i]);</span><br><span class="line">a[<span class="number">7</span>] = _mm256_set1_ps(A[<span class="number">7</span>*c+i]);</span><br><span class="line"></span><br><span class="line">b = _mm256_loadu_ps(B_row);</span><br><span class="line"></span><br><span class="line">o[<span class="number">0</span>] = _mm256_fmadd_ps(a[<span class="number">0</span>], b, o[<span class="number">0</span>]);</span><br><span class="line">o[<span class="number">1</span>] = _mm256_fmadd_ps(a[<span class="number">1</span>], b, o[<span class="number">1</span>]);</span><br><span class="line">o[<span class="number">2</span>] = _mm256_fmadd_ps(a[<span class="number">2</span>], b, o[<span class="number">2</span>]);</span><br><span class="line">o[<span class="number">3</span>] = _mm256_fmadd_ps(a[<span class="number">3</span>], b, o[<span class="number">3</span>]);</span><br><span class="line">o[<span class="number">4</span>] = _mm256_fmadd_ps(a[<span class="number">4</span>], b, o[<span class="number">4</span>]);</span><br><span class="line">o[<span class="number">5</span>] = _mm256_fmadd_ps(a[<span class="number">5</span>], b, o[<span class="number">5</span>]);</span><br><span class="line">o[<span class="number">6</span>] = _mm256_fmadd_ps(a[<span class="number">6</span>], b, o[<span class="number">6</span>]);</span><br><span class="line">o[<span class="number">7</span>] = _mm256_fmadd_ps(a[<span class="number">7</span>], b, o[<span class="number">7</span>]);</span><br><span class="line"></span><br><span class="line">b += <span class="number">8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">_mm256_store_ps(C+i*r, o[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">matrix_mult</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">float</span> *packed_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(<span class="number">8</span>*N*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; j += <span class="number">8</span>) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line"><span class="built_in">memcpy</span>(packed_B+i*<span class="number">8</span>, B+i*N+j, <span class="keyword">sizeof</span>(<span class="type">float</span>)*<span class="number">8</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i += <span class="number">8</span>) &#123;</span><br><span class="line">Mult_8x8(N, N, A+i*N, packed_B, C+i*N+j);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">free</span>(packed_B);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3-4-2-调换循环顺序来解决依赖"><a href="#3-4-2-调换循环顺序来解决依赖" class="headerlink" title="3.4.2 调换循环顺序来解决依赖"></a>3.4.2 调换循环顺序来解决依赖</h5><p>​虽然上面的算法修改结果并不理想，但是也给了我一些启示。既然上面的矩阵方法引入了矩阵乘法的操作来实现所有<code>ThisSum</code>的计算，则同样地，我们是否可以用其他的方法，来列举得到所有的可能值，从而也就可以相应地获得最终的最大值？这也就是第二种想法的由来。</p><p>​注意到，每一次<code>ThisSum</code>都是从单独的一个T[k]元素开始，逐步的累加，那么其实以不同的T[k]开头的值对应的这一组<code>ThisSum</code>是无关的，也就是说外层循环之间是无关的，相关性来自内层循环。利用这一点，我们可以尝试下面的这一思路，简单起见，我们假设<strong>每个向量包含两个元素</strong>。</p><img src="image-20221221223832919.png" alt="image-20221221223832919" style="zoom: 50%;" /><p>​按照上图的方法，我们把8个元素分为4组，每一组用一个向量表示，再设置一个记录<code>max</code>值的向量，包含两个元素。第一次我们将各个值load到这些向量中，与<code>max</code>中的向量比较，只要是大于对应<code>lane</code>的值，则替换，否则保持不变。此后，每一次我们对各个元素左移一位，如图操作，再与前一次得到的向量进行加减。这样每一个向量可以表示两个T[k]对应的<code>ThisSum</code>最终值，每次加法操作表示一次叠加，也就是上图中0可以表示T[0]，每加一次，就从<code>T[0]+T[1]+...+T[i]</code>变为<code>T[0]+T[1]+...+T[i]+T[i+1]</code>，1则表示T[1]开始的。这样我们就可以并行地操作一个向量中包含多个系列的<code>ThisSum</code>值，从而实现向量化并行。</p><img src="image-20221221225007431.png" alt="image-20221221225007431" style="zoom: 50%;" /><p>具体的算法实现如下，实际一个向量包含8个元素：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(l=<span class="number">0</span>; l&lt;N; l++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(k=<span class="number">0</span>; k&lt;N-ROUNDDOWN(l,<span class="number">8</span>); k+=<span class="number">8</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        value2 = _mm256_loadu_ps(T+k+l);</span><br><span class="line">        value[k/<span class="number">8</span>] = _mm256_add_ps(value2, value[k/<span class="number">8</span>]);</span><br><span class="line">        <span class="comment">//value1 = max[i] &gt; value[i]? 0xFFFF:0</span></span><br><span class="line">        value1 = _mm256_cmp_ps(max, value[k/<span class="number">8</span>], _CMP_GT_OS);</span><br><span class="line">        <span class="comment">//max = max &amp; value</span></span><br><span class="line">        max = _mm256_and_ps(value1, max);</span><br><span class="line">        <span class="comment">//value1 = not(value1) &amp; value</span></span><br><span class="line">        value1 = _mm256_andnot_ps(value1, value[k/<span class="number">8</span>]);</span><br><span class="line">        max = _mm256_or_ps(max, value1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​实际的效果上有所提升，但是也并没有老师说的10倍以上，但是至少也有所改进。对于这一个双层循环我能想到的方法也只有这两种，当然通过-O3优化过程中可以看到还是有一些地方可以进一步优化，但是精力有限，就暂时优化到这一层面，进一步的优化还是交给编译器。</p><h2 id="三、效果分析"><a href="#三、效果分析" class="headerlink" title="三、效果分析"></a>三、效果分析</h2><h3 id="1-O-N-6-优化效果"><a href="#1-O-N-6-优化效果" class="headerlink" title="1. O(N^6)优化效果"></a>1. O(N^6)优化效果</h3><p>因为size过大对于O(N^6)的算法十分不友好，<strong>在不加<code>-O3</code>的情况下</strong>，会花费过长时间，故此处选择最大为64：</p><table><thead><tr><th align="left">Size</th><th align="center">16*16</th><th align="center">32*32</th><th align="center">50*50</th><th align="center">64*64</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">1.64*10^-3</td><td align="center">9.52*10^-2</td><td align="center">1.31</td><td align="center">5.77</td></tr><tr><td align="left">With SIMD</td><td align="center">1.10*10^-3</td><td align="center">3.46*10^-2</td><td align="center">3.45*10^-1</td><td align="center">1.30</td></tr><tr><td align="left">Scale</td><td align="center">1.49</td><td align="center">2.75</td><td align="center">3.80</td><td align="center">4.44</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221221234824954.png" alt="image-20221221234824954" height=120 /></td><td align="center"><img src="image-20221221234959581.png" alt="image-20221221234959581" height=120 /></td><td align="center"><img src="image-20221221235149017.png" alt="image-20221221235149017" height=120 /></td><td align="center"><img src="image-20221221235321855.png" alt="image-20221221235321855" height=120 /></td></tr></tbody></table><p>使用<code>-O3</code>进一步优化后：</p><table><thead><tr><th align="left">Size</th><th align="center">32*32</th><th align="center">50*50</th><th align="center">64*64</th><th align="center">100*100</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">2.01*10^-2</td><td align="center">2.98*10^-1</td><td align="center">1.31</td><td align="center">19.3</td></tr><tr><td align="left">With SIMD</td><td align="center">9.02*10^-3</td><td align="center">8.52*10^-2</td><td align="center">3.11*10^-1</td><td align="center">3.29</td></tr><tr><td align="left">Scale</td><td align="center">2.23</td><td align="center">3.50</td><td align="center">4.21</td><td align="center">5.87</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221221234115220.png" alt="image-20221221234115220" height=120 /></td><td align="center"><img src="image-20221221234011974.png" alt="image-20221221234011974" height=120 /></td><td align="center"><img src="image-20221221234338654.png" alt="image-20221221234338654" height=120 /></td><td align="center"><img src="image-20221221234526496.png" alt="image-20221221234526496" height=120 /></td></tr></tbody></table><p>​整体的提速效果随着矩阵的大小而提高，一般能<strong>提高3-4倍</strong>左右，但是由于O(N^6)算法时间复杂度随N增长过快，对过大的矩阵还是会需要很长时间。</p><h3 id="2-O-N-4-优化效果"><a href="#2-O-N-4-优化效果" class="headerlink" title="2. O(N^4)优化效果"></a>2. O(N^4)优化效果</h3><p>对于不加<code>-O3</code>的编译情况：</p><table><thead><tr><th align="left">Size</th><th align="center">50*50</th><th align="center">64*64</th><th align="center">100*100</th><th align="center">500*500</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">4.19*10^-3</td><td align="center">1.12*10^-2</td><td align="center">6.89*10^-2</td><td align="center">44.5</td></tr><tr><td align="left">With SIMD</td><td align="center">3.35*10^-3</td><td align="center">9.17*10^-3</td><td align="center">4.44*10^-2</td><td align="center">25</td></tr><tr><td align="left">Scale</td><td align="center">1.25</td><td align="center">1.22</td><td align="center">1.55</td><td align="center">1.78</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221221235909215.png" alt="image-20221221235909215" height=120 /></td><td align="center"><img src="image-20221222000035239.png" alt="image-20221222000035239" height=120 /></td><td align="center"><img src="image-20221222000231723.png" alt="image-20221222000231723" height=120 /></td><td align="center"><img src="image-20221222000840665.png" alt="image-20221222000840665" height=120 /></td></tr></tbody></table><p>加<code>-O3</code>的情况：</p><table><thead><tr><th align="left">Size</th><th align="center">50*50</th><th align="center">64*64</th><th align="center">100*100</th><th align="center">500*500</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">6.62*10^-4</td><td align="center">1.89*10^3</td><td align="center">1.25*10^-2</td><td align="center">10.6</td></tr><tr><td align="left">With SIMD</td><td align="center">2.55*10^-4</td><td align="center">6.13*10^-4</td><td align="center">3.31*10^-3</td><td align="center">1.67</td></tr><tr><td align="left">Scale</td><td align="center">2.60</td><td align="center">3.83</td><td align="center">3.78</td><td align="center">6.35</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221222001021886.png" alt="image-20221222001021886" height=120 /></td><td align="center"><img src="image-20221222001138189.png" alt="image-20221222001138189" height=120 /></td><td align="center"><img src="image-20221222001257508.png" alt="image-20221222001257508" height=120 /></td><td align="center"><img src="image-20221222001531361.png" alt="image-20221222001531361" height=120 /></td></tr></tbody></table><p>​可以看到，在不加<code>-O3</code>的情况下，提速其实并不理想，但是通过我的加速方法，再通过编译器的加速，发现效果很显著，甚至在500*500时达到了<strong>6倍多</strong>，说明我的加速方法为编译器提供了更好的加速条件。</p><h2 id="四、心得体会"><a href="#四、心得体会" class="headerlink" title="四、心得体会"></a>四、心得体会</h2><p>​在最开始做这个实验时，我其实有些眼高手低，一开始就挑选很大的工程比如数据库着手，想很快看到10倍以上的提速效果。但是现实是，我其实连课上讲解的向量化方法都没有完全弄清晰，一上来就选择这样困难的程序，无疑是很难实现的。后来我也转而打算分析一些库的向量化加速手段，比如Eigen，Pytorch2.0等等，但还是希望能够动手去实现提速，毕竟“纸上得来终觉浅，绝知此事要躬行”，只有自己动手加速过，才有更深的体会。</p><p>​后来我选择了最大子矩阵和的算法，一开始还担心会不会过于简单，和上课讲的之前同学的双边滤波算法、曼德勃罗集这些听起来高大上的算法相形见绌。但是在实际加速过程当中，我也遇到了很多问题，并没有自己想的那样顺利。虽然最后提速效果还是没能达到10倍以上，但是我还是很满意，通过自己的分析，找到了为我自己代码加速的钥匙，其间也花了很多时间不断思考和尝试，尤其在条件判断的向量化这一点上。通过动手尝试，我虽然遇到了很多问题，但是也看到了有很多上课不曾讲到的细节，这些也是只有真的去尝试，才能有所体会的，是我本次实验很大的一个收获。</p><h2 id="五、经验教训"><a href="#五、经验教训" class="headerlink" title="五、经验教训"></a>五、经验教训</h2><p>​在做这个实验时，我遇到了很多问题，包括指令层面、加速算法层面等等。</p><ol><li>在最初使用AVX2的<code>intrinsics</code>时，比较不熟练。我最开始使用int型存储的矩阵，所以需要用到<code>epi32</code>等后缀，但是在这一点上，由于int型变量存在加法&#x2F;乘法的溢出现象，有时候32位的int体现在乘法时，会只支持<code>epi16</code>的乘法，这样就会造成很多复杂的情况。所以最后我还是改用了浮点数，使用ps的后缀，这样就避免了不一致的问题。同时，在使用<code>load</code>和<code>store</code>时，我遇到过一段代码在不同位置，有些可以运行，有些不能的情况，后来发现是在于这两个指令默认是对齐存储的数据，但是很多情况对应的数据是不对齐存储，所以就造成了这一个问题，只需要使用<code>loadu/storeu</code>即能解决问题。</li><li>在探究有条件判断的加速算法时，我最开始没有很好地估计乘法带来的巨大开销，从而在最开始就选错了优化的方向，结果自然是得不偿失。而在代码优化过程中，我发现有时候很微小的调整反映在代码运行速度上，会产生巨大的影响，比如默写<code>load</code>操作的位置是否是精确无重复的等等，需要很审慎地处理。</li><li>在向量化加速时，同样需要注意结果的准确性，很多时候确实速度是提上来了，但是一旦结果出错，所有加速都是无用的，我碰到很多次因为循环展开计数不是8的倍数或者部分值没有及时归0，而造成的结果不一致的问题，需要着重考虑这一点。</li><li>此外，我也尝试了多线程的编程进行加速，但是在本题的循环中效果很不理想，推测是因为频繁的<code>pthread_create</code>的同时还需要对每个线程的<code>MaxSum</code>的加锁互斥，造成了比较大的开销。</li></ol><h2 id="六、参考文献"><a href="#六、参考文献" class="headerlink" title="六、参考文献"></a>六、参考文献</h2><ol><li><p><a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#expand=3828,301,2553&ig_expand=104,6169,1021,3206,3206,156,1029,849,343,383">Intel® Intrinsics Guide</a></p></li><li><p><a href="https://www.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/intrinsics/intrinsics-for-intel-advanced-vector-extensions/intrinsics-for-compare-operations-1/mm-cmp-ps-mm256-cmp-ps.html">_mm_cmp_ps, _m256_cmp_ps</a></p></li><li><p><a href="https://www.coder.work/article/6502434">simd - 如何选择 AVX 比较谓词变体</a></p></li><li><p><a href="https://www.felixcloutier.com/x86/pcmpgtb:pcmpgtw:pcmpgtd">PCMPGTB&#x2F;PCMPGTW&#x2F;PCMPGTD — Compare Packed Signed Integers for Greater Than </a></p></li><li><p><a href="https://www.leiphone.com/category/yanxishe/Puevv3ZWxn0heoEv.html">OpenBLAS项目与矩阵乘法优化</a></p></li><li><p><a href="https://www.cnblogs.com/wangguchangqing/p/5466301.html">SSE指令集学习：Compiler Intrinsic - Brook_icv</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/94649418">AVX &#x2F; AVX2 指令编程</a></p></li><li><p><a href="https://blog.csdn.net/AAAA202012/article/details/123983364">SIMD指令集分析(C&#x2F;C++)</a></p></li><li><p><a href="https://www.cnblogs.com/zyl910/archive/2012/04/19/avx_cmp_imm8.html">AVX指令集中的32种浮点比较关系详解（NaN、无序、有序等）</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> CS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ASM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>指令探索</title>
      <link href="/2022/10/31/%E6%8C%87%E4%BB%A4%E6%8E%A2%E7%B4%A2/"/>
      <url>/2022/10/31/%E6%8C%87%E4%BB%A4%E6%8E%A2%E7%B4%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="x86架构下A系列寄存器算数操作（以ADD指令为例）的提速情况探索"><a href="#x86架构下A系列寄存器算数操作（以ADD指令为例）的提速情况探索" class="headerlink" title="x86架构下A系列寄存器算数操作（以ADD指令为例）的提速情况探索"></a><center>x86架构下A系列寄存器算数操作（以ADD指令为例）的提速情况探索</center></h1><p>课程名称：汇编与接口</p><p>学生姓名：云中君</p><p>学号：********</p><p>邮件地址：********@zju.edu.cn</p><hr><h2 id="一、探索背景"><a href="#一、探索背景" class="headerlink" title="一、探索背景"></a>一、探索背景</h2><p>​印象里是在学习数字逻辑时第一次听说累加器这样一个元件，但是在课上它并不是主角，记得当时老师只是随口一提，然后将大量的篇幅留给了复杂的带进位的加法器的实现，给人一种它没有很大应用场景或者使用效果并不理想的印象。所以当时也没有在意，直到后来在体系结构的课程上讲到了几种ISA class，其中包含了Accumulator类型，课上老师要求将一段简单的加法代码翻译成四种类型，在这个过程中，我发现它与RISC-V的load-store模式有很大的不同，甚至猜测在大量加法时感觉比起load-store可以提速不少，这也让我又一次注意到这个器件。</p><p>​而在本门课的课堂上，在讲x86各个系列寄存器时，老师提到了A系列寄存器Accumulator Register，也就是累加器，它又一次出现在我面前。上课提到它会被自动分配给一些算数指令，也讲到了它的特殊性——<code>add eax, 0xffff7040</code>竟然比<code>add ebx, 0xffff7040</code>要快。老师的解释是编码上eax寄存器单独编码，比ebx短，因而更快，但是没有具体测试，只是参考了intel的手册。这也引起了我的兴趣，很好奇A系列寄存器作为累加器的作用，也想从这一点切入来进行探索，来探究其是否真的能够实现加速，以及指令编码更短是否确实对速度的提升有效果。</p><hr><h2 id="二、探索过程"><a href="#二、探索过程" class="headerlink" title="二、探索过程"></a>二、探索过程</h2><h3 id="1-基于time-h的简易测试程序"><a href="#1-基于time-h的简易测试程序" class="headerlink" title="1. 基于time.h的简易测试程序"></a>1. 基于time.h的简易测试程序</h3><p>​因为此前没有接触过x86汇编的编写，我一时间不知道在什么平台运行汇编指令，以及怎么使用x86汇编指令进行计时。而对于记录程序运行时间，我们此前程序课程上用到最多的是方法是调用C语言的time.h库中的clock()函数，通过<code>程序运行时间=程序运行的时钟周期/每秒的时钟周期数</code>这一公式来实现比较精准的时间计算。</p><p>​但是仅通过C语言来书写，显然不能够实现寄存器层面的绑定。使用C语言的加法，必然会分配到相同的寄存器用于处理。联系到操作系统课程中刚刚学习的内敛汇编相关知识，可以用于RISC-V的指令的执行，那应该也可以使用于x86指令，因此我编写了如下的第一段内联汇编，用以测试。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">asm</span>(</span><br><span class="line">           <span class="string">&quot;add eax, 0xffff7040&quot;</span></span><br><span class="line">           : :</span><br><span class="line">           : <span class="string">&quot;eax&quot;</span></span><br><span class="line">       );</span><br></pre></td></tr></table></figure><p>​在运行时显示了如下错误，显示” too many memory references for add“，问题一定在于内联汇编不合规范。</p><p>![image-20221026215228395](D:\CS\2022 fall-winter\OS\指令探索\image-20221026215228395.png)</p><p>​仔细了解了内联汇编的规范，发现内联汇编似乎支持的是AT&amp;T格式，与我们上课学习的intel格式不同。对于寄存器，需要加%前缀，而为了避免在汇编语句中%表示输入、输出操作数的混淆，需要加%%，而地址则需要加$前缀。这样修改后，仍然会出现错误，显示operand type mismatch for ‘add‘，进一步学习后发现，大多数该类的内联汇编代码实例都将立即数写于寄存器前，故修改如下，可以正常运行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> REPEAT 1000000000</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">clock_t</span> start, end;</span><br><span class="line">    <span class="comment">//bind registers eax/ebx with variables a/b</span></span><br><span class="line">    <span class="keyword">register</span> <span class="type">unsigned</span> <span class="type">int</span> a <span class="title function_">asm</span> <span class="params">(<span class="string">&quot;%eax&quot;</span>)</span>;</span><br><span class="line">    <span class="keyword">register</span> <span class="type">unsigned</span> <span class="type">int</span> b <span class="title function_">asm</span> <span class="params">(<span class="string">&quot;%ebx&quot;</span>)</span>;</span><br><span class="line"></span><br><span class="line">    start = clock();</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">long</span> <span class="type">int</span> i=<span class="number">0</span>; i&lt;REPEAT; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">asm</span>(</span><br><span class="line">            <span class="string">&quot;add %%eax,$0xffff7040&quot;</span></span><br><span class="line">            : :</span><br><span class="line">            : </span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;EAX: time is %f s\n&quot;</span>, (<span class="type">double</span>)(<span class="number">1.0</span>*(end-start)/CLOCKS_PER_SEC));</span><br><span class="line"></span><br><span class="line">    start = clock();</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">long</span> <span class="type">int</span> i=<span class="number">0</span>; i&lt;REPEAT; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">asm</span>(</span><br><span class="line">            <span class="string">&quot;add $0xffff7040,%%ebx&quot;</span></span><br><span class="line">            : :</span><br><span class="line">            : </span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">    end = clock();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;EBX: time is %f s\n&quot;</span>, (<span class="type">double</span>)(<span class="number">1.0</span>*(end-start)/CLOCKS_PER_SEC));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​使用gcc编译后，对其进行反汇编，查看该程序对应的x86汇编代码，可以看到对应指令就是需要测试的指令。</p><img src="image-20221027202448227.png" alt="image-20221027202448227" style="zoom:33%;" /><img src="image-20221027202555201.png" alt="image-20221027202555201" style="zoom: 33%;" /><p>​在Linux Ubuntu环境下每条指令循环十亿次，获得基本的速度情况，确实发现就这一条ADD指令来说EAX要快于EBX，但是相对来说相差并不明显。</p><img src="image-20221027203920549.png" alt="image-20221027203920549" style="zoom: 33%;" /><p>​将EAX&#x2F;EBX的测试顺序交换，测试速度情况，以排除顺序的问题。</p><img src="image-20221027204440953.png" alt="image-20221027204440953" style="zoom:33%;" /><p>​但是发现似乎对于反向顺序的测试，结果刚好相反，而且即使我在不同时间段、不同电脑运行模式以及不同重复次数的测试下得到的结果也类似</p><p>​下图为电脑静音模式下的结果。</p><img src="image-20221027210712388.png" alt="image-20221027210712388" style="zoom:33%;" /><p>​但是这样判断显然存在一些问题，也就是我仅仅执行了少数几次程序，对于结果比较明显（比如运行十次，每次都是eax快于ebx）的情况确实可以进行初步判断，但是对于一些结果有浮动的情况不能精确判断，那么仅仅运行10次并不具有参考意义。对此，我编写了一个shell脚本用于批量测试，实现运行多次程序，并求出结果的平均数（其中测试程序<code>test</code>输出<code>ebx运行周期数/eax运行周期数</code>）。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">!/bin/bash</span></span><br><span class="line">re=0</span><br><span class="line">div=**** #the number of times for loop</span><br><span class="line">for ((i=0;i&lt;div;i++))</span><br><span class="line">do</span><br><span class="line">    a=`./$1`#for specific test program</span><br><span class="line">    re=$(echo &quot;$a+$re&quot; | bc)</span><br><span class="line">done</span><br><span class="line">re=$(echo &quot;scale=5;$re/$div&quot; | bc)</span><br><span class="line">echo $re</span><br></pre></td></tr></table></figure><table><thead><tr><th>循环次数</th><th>EBX时间&#x2F;EAX时间（EAX先执行）</th><th>EBX时间&#x2F;EAX时间（EBX先执行）</th><th>平均</th></tr></thead><tbody><tr><td>10^4</td><td>0.98396</td><td>1.07485</td><td>1.029405</td></tr><tr><td>10^5</td><td>0.99509</td><td>1.01436</td><td>1.004725</td></tr><tr><td>10^6</td><td>0.99185</td><td>1.01492</td><td>1.003385</td></tr><tr><td>10^7</td><td><strong>1.00085</strong></td><td>1.00216</td><td>1.001505</td></tr><tr><td>10^8</td><td>0.99907</td><td>1.00442</td><td>1.001745</td></tr></tbody></table><p>​怪异的是，在隔一段时间再去测试时，在测试重复次数较小时，结果情况又颠倒，eax先运行则eax慢于ebx，反之则快于ebx。具体情况如上表所示，由于重复次数过大会导致测试时间过长，而过小则很不精确，故此处选择10^4~10^8四个阶段进行测试。值得注意的是10^7时，结果显示均大于1，但是10^8时又不一样，则并不是随着循环次数增大而产生提速效果，显然这样的测试结果并不能十分清晰地说明问题。</p><h3 id="2-测试前后不一致的分析与改进"><a href="#2-测试前后不一致的分析与改进" class="headerlink" title="2. 测试前后不一致的分析与改进"></a>2. 测试前后不一致的分析与改进</h3><p>​此前在数据结构与算法等课程上，对不同数据结构的性能测试上，我也普遍采用了这样一种软件层面的计时方法，那么此处的前后不一致让我着实摸不着头脑。</p><p>​对这种情况，我猜想：</p><ol><li>可能是因为调用的clock函数计时并不精准，或者在使用clock函数时，其中一些指令与eax&#x2F;ebx的测试代码在流水线中运行存在依赖&#x2F;冲突；</li><li>可能是因为同时进行测试，导致部分寄存器的情况在进入eax循环和进入ebx循环中时存在区别，且也可能存在指令依赖，但是分开测试又会存在不同时运行，CPU的状态可能差别较大的问题。</li></ol><p>​仅仅推测不能解决问题，故下面对这两个猜想进行逐一的分析和验证。</p><h4 id="2-1-替换测试时间方法"><a href="#2-1-替换测试时间方法" class="headerlink" title="2.1 替换测试时间方法"></a>2.1 替换测试时间方法</h4><p>​仔细查看了反汇编代码，在main函数中clock()函数调用实际是执行了<code>callq  1060 &lt;clock@plt&gt;</code>这一条指令，也就是调用<code>&lt;clock@plt&gt;</code>中的函数，其对应的代码如下。</p><img src="image-20221027212618565.png" alt="image-20221027212618565" style="zoom: 25%;" /><p>​其中执行了<code>bnd jmpq *0x2f5d</code>，而这一指令似乎是一个系统调用，对于反汇编得到的代码来说，不能找到对应的代码。故尝试用gdb确认这一步具体的操作。</p><img src="image-20221027215405682.png" alt="image-20221027215405682" style="zoom: 25%;" /><p>​但是发现进入到这一条指令，就显示<code>sysdeps...</code>等，推测是进入了clock.c进行执行，那么继续从clock.c中探究似乎并没有意义，因为通过修改clock.c的代码来改善这一情况并不现实；而对于原有测试指令，也并不能再进一步精简。</p><p>​对此，我在网上查资料的过程中，看到很多资料也指出使用软件方式计时可能会有较大的误差，并不精确。那么在对于指令速度的测试上，可能更适合用硬件层面的指令来完成。</p><p>​要获取运行时间，在汇编中还有许多方法。其中一种是直接使用int 0x80调用time.c，进行系统调用，那么似乎与前面的clock()方法调用clock.c没有区别。而在查阅资料过程中，我发现在intel汇编指令中，指令<code>rdtsc</code>也可以用于获得CPU从上电开始总共经历的时钟周期数，它是隐含操作数指令，会将周期数高32位存在edx寄存器，低32位存在eax寄存器。</p><p>​则两次使用该指令，并通过两处相减即可获取测试代码运行的时钟周期数，也就相应地可以求出运行时间，从而更准确地比较指令运行速度。但是进一步深入学习过程中，我发现由于CPU乱序执行的影响，要保证这一刻流水线已排空，即<code>rdtsc</code>要测量的指令已执行完，才能获取准确结果。所以<code>rdtsc</code>指令需要配合<code>cpuid</code>或<code>lfence</code>指令才能精确获取时间，而intel也提供了<code>rdtscp</code>指令（rdtsc+cpuid)。因此将clock()替换为如下函数进行测试。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;linux/types.h&gt;</span></span></span><br><span class="line">__u64 <span class="title function_">rdtsc</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">        __u32 lo,hi;</span><br><span class="line"></span><br><span class="line">        __asm__ __volatile__</span><br><span class="line">        (</span><br><span class="line">         <span class="string">&quot;rdtscp&quot;</span>:<span class="string">&quot;=a&quot;</span>(lo),<span class="string">&quot;=d&quot;</span>(hi)</span><br><span class="line">        );</span><br><span class="line">        <span class="keyword">return</span> (__u64)hi&lt;&lt;<span class="number">32</span>|lo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>循环次数</th><th>EBX时间&#x2F;EAX时间（EAX先执行）</th><th>EBX时间&#x2F;EAX时间（EBX先执行）</th><th>平均</th></tr></thead><tbody><tr><td>10^5</td><td>0.99622</td><td>1.23607</td><td>1.116145</td></tr><tr><td>10^6</td><td>1.00488</td><td>1.00189</td><td>1.003385</td></tr><tr><td>10^7</td><td>1.00311</td><td>0.99799</td><td>1.00055</td></tr><tr><td>10^8</td><td>1.00011</td><td>0.99999</td><td>1.00005</td></tr></tbody></table><p>部分结构截图如下。（其中test_rdtsc为b先于a，test_r为a先于b）</p><p>10^5:</p><img src="image-20221029200156014.png" alt="image-20221029200156014" style="zoom:33%;" /><p>10^6:</p><img src="image-20221029172631808.png" alt="image-20221029172631808" style="zoom:33%;" /><p>10^7:</p><img src="image-20221029174444013.png" alt="image-20221029174444013" style="zoom:33%;" /><p>10^8:</p><img src="image-20221029200307977.png" alt="image-20221029200307977" style="zoom:33%;" /><p>​相对来说，使用rdtsc指令测试结果上来说也不尽人意，随机性依然较强，每次得到的时间比都不同。分析原因，因为代码以及反汇编除了测试的add指令并无不同，可能依然是由于不同顺序执行下存在指令的依赖，导致流水线上的乱序执行和并发时存在一些需要stall的地方，从而使得整体上的表现会因为顺序而不同；同时CPU的状态变化可能也会导致一些随机性。但是回过头综合看两个顺序的指令执行效果，不论是使用time.h库还是rdtsc指令，在不同循环次数下，不同顺序的比例取平均值，在总体上还是有所提升的（按照结果大约提升0.1%~1%，实际情况下更复杂，可能会更低，不过这样的提升也相对可观）。</p><h4 id="2-2-单独测试EAX-x2F-EBX"><a href="#2-2-单独测试EAX-x2F-EBX" class="headerlink" title="2.2 单独测试EAX&#x2F;EBX"></a>2.2 单独测试EAX&#x2F;EBX</h4><p>​对于第二个想法，即可能由于顺序执行时每个指令测试时寄存器状况不同的情况，我修改了部分的代码（使其输出各自测试的时间长度），并使用前面的shell脚本进行计算，即可得到两个寄存器测试的运行时间。</p><table><thead><tr><th>循环次数</th><th>EAX(ms)</th><th>EBX(ms)</th></tr></thead><tbody><tr><td>10^6</td><td>1.5227</td><td>1.6671</td></tr><tr><td>10^7</td><td>15.239</td><td>15.334</td></tr><tr><td>10^8</td><td>152.94</td><td>154.38</td></tr><tr><td>10^9</td><td>1536.7</td><td>1537.5</td></tr></tbody></table><p>部分测试图片（由1中修改而来，命名问题，test_EAX实际测了EBX，test_EBX实际测了EAX）</p><p>10^6:</p><img src="image-20221029210753405.png" alt="image-20221029210753405" style="zoom:33%;" /><p>10^7:</p><img src="image-20221029210728451.png" alt="image-20221029210728451" style="zoom:31%;" /><p>10^8:</p><img src="image-20221029210613654.png" alt="image-20221029210613654" style="zoom:33%;" /><p>10^9:</p><img src="image-20221029210125546.png" alt="image-20221029210125546" style="zoom:33%;" /><p>​由此结果可以看到，程序时间随循环次数增长呈近似线性的增长，EAX平均时间短于EBX。这也从另一方面证实了我们最开始提出的假设，即对于ADD指令，确实使用eax寄存器能相对更快。</p><h3 id="3-x86汇编程序直接测试"><a href="#3-x86汇编程序直接测试" class="headerlink" title="3. x86汇编程序直接测试"></a>3. x86汇编程序直接测试</h3><p>​鉴于上述都是基于C语言的操作，依然可能会有较多无关指令无法彻底排除。而有了前面的基础，直接使用汇编代码进行测试也就相对易于实现了（虽然由于没有x86汇编的基础，在起步时依然比较困难，每一步都不太熟悉）。依据老师上课讲的指令以及一些网络资料，我尝试着编写了这样一段程序（部分重复代码详见附件）。主要功能上是实现一个<code>add eax， 0xffff7040</code>的循环，并用rdtscp进行记录并输出。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">; test.asm </span><br><span class="line">section .data              ; 数据段声明</span><br><span class="line">        msg db &quot;&quot;, 0xA     ; 要输出的字符串</span><br><span class="line">        len equ $ - msg                 ; 字串长度</span><br><span class="line">a dq 1</span><br><span class="line">b dq 1</span><br><span class="line">ta dq 1</span><br><span class="line">td dq 1</span><br><span class="line">section .bss</span><br><span class="line">    num    resd 1</span><br><span class="line">    buffer resb 10</span><br><span class="line">section .text            ; 代码段声明</span><br><span class="line">global _start            ; 指定入口函数</span><br><span class="line">_start:                  ; 在屏幕上显示一个字符串</span><br><span class="line">;eax test</span><br><span class="line">rdtscp</span><br><span class="line">mov qword[ta], rax</span><br><span class="line">mov qword[td], rdx</span><br><span class="line"></span><br><span class="line">;this is the loop for add</span><br><span class="line">xor edx, edx</span><br><span class="line">xor eax, eax</span><br><span class="line">loop_1:inc edx</span><br><span class="line">add eax, 0xffff7040</span><br><span class="line">cmp edx, 0xfffff</span><br><span class="line">jbe loop_1</span><br><span class="line">rdtscp</span><br><span class="line">shl rdx, 0x20</span><br><span class="line">mov rcx, rax</span><br><span class="line">add rcx, rdx</span><br><span class="line">mov rax, [ta]</span><br><span class="line">mov rdx, [td]</span><br><span class="line">shl rdx, 0x20</span><br><span class="line">add rdx, rax</span><br><span class="line">sub rcx, rdx</span><br><span class="line">enda:</span><br><span class="line">mov eax, ecx</span><br><span class="line">mov esi, buffer</span><br><span class="line">call int_to_string</span><br><span class="line"></span><br><span class="line">mov edx, ecx     ; 参数三：字符串长度</span><br><span class="line">        mov ecx, eax     ; 参数二：要显示的字符串</span><br><span class="line">        mov ebx, 1       ; 参数一：文件描述符(stdout) </span><br><span class="line">        mov eax, 4       ; 系统调用号(sys_write) </span><br><span class="line">        int 0x80         ; 调用内核功能</span><br><span class="line"></span><br><span class="line">mov edx, len     ; 参数三：字符串长度</span><br><span class="line">        mov ecx, msg     ; 参数二：要显示的字符串</span><br><span class="line">        mov ebx, 1       ; 参数一：文件描述符(stdout) </span><br><span class="line">        mov eax, 4       ; 系统调用号(sys_write) </span><br><span class="line">        int 0x80         ; 调用内核功能</span><br><span class="line"></span><br><span class="line">nop ;此处省略了多个nop，用于让流水线完成</span><br><span class="line">;...用于测试ebx，与前面eax一样</span><br><span class="line"></span><br><span class="line">; Input:</span><br><span class="line">; eax = integer value to convert</span><br><span class="line">; esi = pointer to buffer to store the string in (must have room for at least 10 bytes)</span><br><span class="line">; Output:</span><br><span class="line">; eax = pointer to the first character of the generated string</span><br><span class="line">; ecx = length of the generated string</span><br><span class="line">int_to_string:</span><br><span class="line">;来自 https://www.codingdict.com/questions/45480</span><br><span class="line">;此处省略过程，仅仅用于将int转化为字符串</span><br></pre></td></tr></table></figure><p>​使用nasm编译，并采用ld链接，可以成功运行，运行结果如下。</p><img src="image-20221029212543267.png" alt="image-20221029212543267" style="zoom: 50%;" /><p>​下面是将两端测试单独分开执行的结果。由于单独执行时，使用脚本出现了输出处理的问题（因为程序中调用系统调用时是按照输出字符串格式输出，由于个人汇编能力限制，没办法直接输出int，而这个格式在shell处理时就无法读入），所以此处给出了手动运行的代码。</p><img src="image-20221029214152011.png" alt="image-20221029214152011" style="zoom: 50%;" /><p>​总体上也是EAX快于EBX，虽然偶尔会出现较怪异的情况，猜测是使用rdtsc指令时，寄存器值存在溢出，或者产生了其他中断&#x2F;stall，但不影响整体的情况。</p><h3 id="4-进一步分析编码因素"><a href="#4-进一步分析编码因素" class="headerlink" title="4. 进一步分析编码因素"></a>4. 进一步分析编码因素</h3><p>​基于上面的测试，可以看到对于加法这类指令，确实使用EAX会快于EBX等其他寄存器。对于这一情况，我们的解释是由于编码的问题，使用eax的指令编码将比使用其他寄存器短一字节，这一点可以在c语言转汇编时清晰地看到，<code>add eax, 0xffff7040</code>的编码是<code>05 40 70 ff</code>，而<code>add ebx, 0xffff7040</code>的编码则是<code>81 c3 40 70 ff</code>。</p><img src="image-20221027201332084.png" alt="image-20221027201332084" style="zoom:33%;" /><img src="image-20221027201313076.png" alt="image-20221027201313076" style="zoom:33%;" /><p>​那么很自然地想到，如果我们人为将eax的编码加一字节，程序的运行结果又会如何？联系到老师上课讲的对于x86指令的格式，可以通过加前缀的方式来扩展指令，从而指定一些指令的具体使用情况。而许多指令在实际编码时也会加66前缀来实现对齐。</p><img src="image-20221029215825261.png" alt="image-20221029215825261" style="zoom: 33%;" /><p>​尝试使用在操作数前加66H，因为66H用于改变操作数size，那对于64位模式下，改为32位，加上66H不会产生影响。而要增加前缀，首先也需要一个空位进行修改，否则会出现修改后使得前面指令出现异常的情况，而这一个空白位，结果试验，可以由nop指令来提供，故改1中测试代码的内联汇编为如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">asm</span>(</span><br><span class="line">        <span class="string">&quot;nop\n&quot;</span></span><br><span class="line">        <span class="string">&quot;add $0xffff7040,%%eax&quot;</span></span><br><span class="line">        : :</span><br><span class="line">        : </span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>​经过反汇编，可以看到结果上确实能够多出一字节。</p><img src="image-20221029221528937.png" alt="image-20221029221528937" style="zoom:33%;" /><p>​那么相应地，我们可以修改其可执行文件中的编码，来实现指令编码的延长。</p><img src="image-20221030002951218.png" alt="image-20221030002951218" style="zoom:33%;" /><p>​在修改之前，我先在Online-Assembler-and-Disassembler中测试了是否可以翻译，发现编码<code>66054070ffff</code>对应的指令是<code>add ax, 0x7040</code>，显然与原指令不同，对此我仔细对照了操作数前缀的格式表，发现对于前缀66，只能用于64位模式下转为16位（那也就是前面转化成ax的原因），那么补充66H显然会造成显著的指令意义上的区别，故寻求其他填充前缀。</p><img src="image-20221029221404819.png" alt="image-20221029221404819" style="zoom: 33%;" /><p>​印象中上课讲66H前缀时，也讲到寻址模式相关的前缀67H，是用于64位下设置寻址模式为32位。而对于这条add指令，显然不涉及寻址，仅仅只需做寄存器值和立即数的加法，那么，我们加上这样的前缀，似乎不会影响整条指令的功能。同样，我们先用工具Online-Assembler-and-Disassembler翻译，得到结果如下图。</p><img src="image-20221030004403672.png" alt="image-20221030004403672" style="zoom: 33%;" /><p>​可以看到，这样的前缀并不影响指令内涵，同样的，我们修改预留好的nop位为67H。根据054070对应的ASCII码，找到对应的指令，并进行修改。</p><img src="image-20221030004922599.png" alt="image-20221030004922599" style="zoom:33%;" /><p>​修改为67H，这样既不影响前面指令，也实现了延长指令编码的功能。</p><img src="image-20221030004940256.png" alt="image-20221030004940256" style="zoom: 33%;" /><p>​使用objdump工具获取对应的汇编指令，查看指令是否出现更改。</p><img src="image-20221030005340975.png" alt="image-20221030005340975" style="zoom: 33%;" /><p>​可以发现在AT&amp;T格式下，指令显示了addr32前缀，这并不影响其基本功能。但是为了确保其功能确实并没有改变，还是使用gdb调试，检验操作后的寄存器值，以进一步证实这一猜想。</p><img src="image-20221030005937822.png" alt="image-20221030005937822" style="zoom: 25%;" /><img src="image-20221030010016841.png" alt="image-20221030010016841" style="zoom:25%;" /><p>​执行前后，rax寄存器值由0xca0到0xffff7ce0，确实是加了0xffff7040，也就说明指令功能确实没有变化。我们相应的进行与1-3步中的测试，就可以检验编码是否确实是影响这条指令运行速度的因素。我们修改shell以支持顺序进行测试。对此我们运行了5次整体测试程序（电脑静音模式）和5次电脑增强模式下的测试。</p><img src="image-20221030141558674.png" alt="image-20221030141558674" style="zoom: 33%;" /><img src="image-20221030141824120.png" alt="image-20221030141824120" style="zoom:33%;" /><img src="image-20221030142908030.png" alt="image-20221030142908030" style="zoom: 33%;" /><img src="image-20221030144125474.png" alt="image-20221030144125474" style="zoom:33%;" /><img src="image-20221031132940456.png" alt="image-20221031132940456" style="zoom: 28%;" /><img src="image-20221031133048763.png" alt="image-20221031133048763" style="zoom: 28%;" /><p>​整体上看，额外编码后的add指令在运行时间上有所延长，但是多数情况下，eax+op的执行时间短于ebx指令的执行时间。这也说明，指令编码长短的因素确实会影响指令执行的速度，但是具体的影响因素从实验结果中却较难分析，因为我们此处的测试不可能保证三个测试循环同时运行，则不同时间的CPU状态并不相同，且这仅仅是我个人电脑的运行结果，可能在其他具有不同硬件情况的平台上运行的结果又不相同；同时，即使保证了同时运行（尝试过采用多线程进行测试），每一个线程都可能有不同的资源分配情况，则也无法完全找到情况相同的运行环境，所以我推测这也是很多时候测试结果产生波动和随机性分布的原因，但这一点上我如今依然没有找到最合适的解决方案，希望在未来的学习和研究中能够继续深入。</p><hr><h2 id="三、效果分析"><a href="#三、效果分析" class="headerlink" title="三、效果分析"></a>三、效果分析</h2><p>​详细的数据见二中的分析。整体的结果呈现上，A系列寄存器（以EAX为例）在加法ADD指令上的表现优于B系列寄存器的表现，且编码长度因素在这个方面存在一定的影响。同理，对于C等其他系列寄存器的表现上，也可以以此类推，但是由于并没有实际进行测试，所以尚不能下断言；同样地，对于sub等其他算数指令的效果，也只能以add为例进行类推，推测应当有类似的结果，但是也仍然需要进一步测试确定。</p><h2 id="四、实验体会"><a href="#四、实验体会" class="headerlink" title="四、实验体会"></a>四、实验体会</h2><p>​最开始进行探索时，我感觉选择这样一条十分基础的指令，从这样一个小的方面切入，会不会过于简单，没有什么内容，其实心里也是比较忐忑的。但是在探索过程中，实际花费的时间和遇到的困难远远超过了我的预期，原来一条十分基本的指令深入下去，也能有许多意想不到的收获。比如最开始性能验证时，结果随机性较大，并没有很明显的一边倒（即eax快于ebx），这一度也让我十分困扰。为了实事求是，前面结果的不尽人意也敦促我继续提出猜想，并额外采取了其他方式进行进一步验证，而这一环节过程中也产生了一系列问题，这些问题也促使我继续探索，继续思考，不断深入。</p><p>​因为结果上仍然有不确定和偶然因素存在，整个测试过程也可能因为实验平台的区别而存在不一样的可能，我无法100%下断言我得出的结论是正确的、符合实际情况的。虽然如此，在整体的探索过程当中，我也有机会对此前课程上数据结构性能测试准确性一直存在的疑问进行了更细致地探讨和分析，也用到了许多不同课程中学到的知识，进行综合地使用和贯通；同时也在写汇编代码过程中，进一步理解了老师上课讲到的许多指令的用法，虽然之前没有基础，但是通过这次实验的动手实践，我也能够初步编写基本的程序。这些都是这次探索中我感觉到最有价值的事。虽然花费了很多时间，但是我也收获了很多，让我真正有机会跳开很多课程繁忙密集的实验安排，去反思过去遇到的一直没有时间去细想的问题。</p><h2 id="五、经验教训"><a href="#五、经验教训" class="headerlink" title="五、经验教训"></a>五、经验教训</h2><ol><li><p>最开始编写测试时间程序时，因为想测试同一条指令，担心每次add导致eax寄存器的值可能会溢出，故在循环内，将eax&#x2F;ebx绑定的变量a&#x2F;b赋值为0，这样似乎能保证每次都是0+0xffff7040，但是后来发现，这样反汇编结果中有mov $0x0,%eax&#x2F;ebx这一条，虽然编码长度一致，但是有可能影响到整体的测试。在实际测试过程中，也确实发现，当我把eax和ebx测试的顺序颠倒后，结果上却也正好相反，且相差甚大，故最后删除了这两条赋值语句，继续进行测试。</p><img src="image-20221027201332084.png" alt="image-20221027201332084" style="zoom:33%;" /><img src="image-20221027201313076.png" alt="image-20221027201313076" style="zoom:33%;" /></li><li><p>最开始将两个指令的测试放在一个程序中，我比较疑惑是否会在前后产生指令上的依赖，因此我尝试了将两个测试放在两个线程中运行，虽然确实将两端测试分开了，但是创建线程之后具体指令执行的资源分配情况仍然难以确切地知道，所以最后放弃了这一测试方法。</p><img src="image-20221031141707762.png" alt="image-20221031141707762" style="zoom:30%;" /></li><li><p>在使用rdtscp指令测试时间时，因为该指令会将得到的硬件时钟数放在两个寄存器中，我先直接尝试了在该指令后，对rdx左移32位，再加上rax，这样就获得了准确的时钟周期。但是这样在测试上，又额外加入了这几条指令的时钟周期，且在流水线中执行时，可能会产生冲突&#x2F;stall等情况，从而影响测试的准确性（实际测试如图，造成了不确定的结果，得不到任何结论，甚至可能ebx更快），但是这两个寄存器的值必须得保存下来，不然在循环中，包括第二次调用rdtscp指令时，他们都会被修改。故最后只好采用先将两个寄存器暂存在data段定义的变量中，以尽可能减少误差。</p><img src="image-20221029151134159.png" alt="image-20221029151134159" style="zoom:50%;" /></li></ol><h2 id="六、参考文献"><a href="#六、参考文献" class="headerlink" title="六、参考文献"></a>六、参考文献</h2><p>1.<a href="https://zhuanlan.zhihu.com/p/242702373">测量CPU的利器 - TSC (Time Stamp Counter) - 知乎 (zhihu.com)</a></p><p>2.<a href="https://www.codingdict.com/questions/45480">使用x86 32位Linux sys_write（NASM）打印整数 (codingdict.com)</a></p><p>3.<a href="https://blog.csdn.net/xfcyhuang/article/details/6230021">X86指令内幕 ——深入了解Prefix_xfcyhuang的博客-CSDN博客_prefix汇编</a></p><p>4.<a href="https://shell-storm.org/online/Online-Assembler-and-Disassembler">https://shell-storm.org/online/Online-Assembler-and-Disassembler</a></p><p>5.<a href="https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html">Intel® 64 and IA-32 Architectures Software Developer Manuals</a></p>]]></content>
      
      
      <categories>
          
          <category> CS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ASM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>七律·忽觉秋凉</title>
      <link href="/2022/10/03/poem_2/"/>
      <url>/2022/10/03/poem_2/</url>
      
        <content type="html"><![CDATA[<h2 id="七律·忽觉秋凉"><a href="#七律·忽觉秋凉" class="headerlink" title="七律·忽觉秋凉"></a><center>七律·忽觉秋凉</center></h2><center>计日归期今又近，暑天潇洒去难留。</center><center>结庐山境浮新雨，横笛云林唤别愁。</center><center>一绺金风轻入户，半年心事散成秋。</center><center>凭将凉意问来处，几点残灯上客舟。</center><h2 id="跋"><a href="#跋" class="headerlink" title="跋"></a>跋</h2><p>搬运一些旧作~</p><h2 id="平台同步"><a href="#平台同步" class="headerlink" title="平台同步"></a>平台同步</h2><p>西窗：也无风雨_<br>微信读书：也无风雨<br>微信公众号：凌云漫谈</p>]]></content>
      
      
      <categories>
          
          <category> 诗词 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 律诗 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>行军集</title>
      <link href="/2022/10/02/collection_1/"/>
      <url>/2022/10/02/collection_1/</url>
      
        <content type="html"><![CDATA[<h2 id="•词"><a href="#•词" class="headerlink" title="•词"></a>•词</h2><h3 id="破阵子"><a href="#破阵子" class="headerlink" title="破阵子"></a><center>破阵子</center></h3><p>云邈但凭龙翥，峰危气胜熊罴。骁浪长鲸驱海兽，梦里秋风会畎夷。豪情荡濬池。</p><p>词笔难言澎湃，行军方晓鸿姿。夕照曾经镶赤壁，也映书生羡骠骑。柔乡今日辞。</p><h3 id="浪淘沙令·次韵柳永"><a href="#浪淘沙令·次韵柳永" class="headerlink" title="浪淘沙令·次韵柳永"></a><center>浪淘沙令·次韵柳永</center></h3><p>鱼雁寄征人。装束精神。炎曦论剑置罗裀。浩唱东坡随太白，豪旷浑身。</p><p>南浦泪衫裙。捣练声新。飞蓬何处尽浮尘。应耐尊前空对月，笔断含颦。</p><h3 id="行香子·次韵东坡"><a href="#行香子·次韵东坡" class="headerlink" title="行香子·次韵东坡"></a><center>行香子·次韵东坡</center></h3><p>训勖方终。阳景酣浓。汗如星、何惧途穷。少年肝胆，谁羡桐封。对胡天雪，吹霜角，射轩龙。</p><p>带三尺剑，听古笙钟。赏蔷薇、也爱戎风。又披迷彩，暂出樊笼。作千秋客，邀侠士，斗蹻容。</p><h3 id="水龙吟•有感军训尾声"><a href="#水龙吟•有感军训尾声" class="headerlink" title="水龙吟•有感军训尾声"></a><center>水龙吟•有感军训尾声</center></h3><p>斜阳常引烟波路，桥底金风迟渡。秋蛩声晚，催人铸剑，明朝起舞。好立天穹，空山自在，游蜂如故。叹不平事多，无须回首，懒寻觅、栖鸾处。</p><p>只问人生几度。似梅寒、敢争新露。营中情义，怕逢阙月，难留君驻。落寞关山，霓虹尘肆，后来相顾。记军装笔挺，平生难再，赴当时路。</p><h2 id="•诗"><a href="#•诗" class="headerlink" title="•诗"></a>•诗</h2><h3 id="五律·军训遇雨"><a href="#五律·军训遇雨" class="headerlink" title="五律·军训遇雨"></a><center>五律·军训遇雨</center></h3><center>越地多风雨，霖霪浸甲裳。</center><center>水高渔父喜，云近学鸠狂。</center><center>既得凌霄志，当期烈日长。</center><center>龙门虽好跃，不纳折腰郎。</center><h3 id="七律•军训途中作"><a href="#七律•军训途中作" class="headerlink" title="七律•军训途中作"></a><center>七律•军训途中作</center></h3><center>翡玉盈盈褚褐藏，清秋万里送军忙。</center><center>影遮老树何需护，风曳江离尚自强。</center><center>薰草林间蛩唱响，蜻蜓翼下好乘凉。</center><center>不忧雨打空狼狈，燕颔书生且耀光。</center><h3 id="七律•致教官"><a href="#七律•致教官" class="headerlink" title="七律•致教官"></a><center>七律•致教官</center></h3><center>我本无情沧浪客，敢挥万将自疏狂。</center><center>凝眸秋雨泠风起，笑靥春烟碧柳扬。</center><center>踏雪风花尘不染，称雄逐鹿剑轻藏。</center><center>海潮愿忍鹏腾远，惟寄行云送少郎。</center><h2 id="跋"><a href="#跋" class="headerlink" title="跋"></a>跋</h2><p>随便写的，有些也是为了卷通讯稿。后来发现，好像那些审稿的牛人都不待见我，那我就不去迎合他们了，就写点自己想写的吧。纪念我的军训时光。（搬运旧作ing）</p><h2 id="平台同步"><a href="#平台同步" class="headerlink" title="平台同步"></a>平台同步</h2><p>西窗：也无风雨_<br>微信读书：也无风雨<br>微信公众号：凌云漫谈</p>]]></content>
      
      
      <categories>
          
          <category> 诗词 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无题：记《隐入尘烟》</title>
      <link href="/2022/10/01/poem_1/"/>
      <url>/2022/10/01/poem_1/</url>
      
        <content type="html"><![CDATA[<h2 id="无题"><a href="#无题" class="headerlink" title="无题"></a><center>无题</center></h2><center>赶驴垄上共春耕，陋室归来有笑声。</center><center>各自因缘人尽弃，此间极乐苦中生。</center><center>成双喜字折还皱，入水新衣洗不清。</center><center>明灭残光终黯淡，尘烟漫漫葬无名。</center><h2 id="跋"><a href="#跋" class="headerlink" title="跋"></a>跋</h2><p>前些天趁着假期，在图书馆看完了《隐入烟尘》，为之动容，浅浅写了这一首不甚满意的七律（对仗都没到位）。但也不忍再改，怕心情又难平复，谨以此纪念那隐入尘烟的《隐入尘烟》。</p><h2 id="平台同步"><a href="#平台同步" class="headerlink" title="平台同步"></a>平台同步</h2><p>西窗：也无风雨_<br>微信读书：也无风雨<br>微信公众号：凌云漫谈</p>]]></content>
      
      
      <categories>
          
          <category> 诗词 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 律诗 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写在最前面</title>
      <link href="/2022/10/01/hello_world/"/>
      <url>/2022/10/01/hello_world/</url>
      
        <content type="html"><![CDATA[<p>欢迎来到也无风雨的Blog！这里大概率更新一点诗词（可能会搬运一些之前写的xs），小概率会放几篇CS相关文章（因为本人专业能力有限，只懂些皮毛），偶尔会写点散文&#x2F;议论（大概率不太会有）。</p><h3 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h3><p>ZJU菜菜一枚</p><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>可能会搬运之后诗友们的集子~（也许吧）</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
