<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>向量化加速:尝试基于SIMD加速最大子矩阵和问题</title>
      <link href="/2022/12/28/%E6%9C%80%E5%A4%A7%E5%AD%90%E7%9F%A9%E9%98%B5%E5%92%8C%E9%97%AE%E9%A2%98%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96%E5%8A%A0%E9%80%9F%E6%8E%A2%E7%A9%B6%E4%B8%8E%E6%89%A9%E5%B1%95/"/>
      <url>/2022/12/28/%E6%9C%80%E5%A4%A7%E5%AD%90%E7%9F%A9%E9%98%B5%E5%92%8C%E9%97%AE%E9%A2%98%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96%E5%8A%A0%E9%80%9F%E6%8E%A2%E7%A9%B6%E4%B8%8E%E6%89%A9%E5%B1%95/</url>
      
        <content type="html"><![CDATA[<h1 id="最大子矩阵和问题的向量化加速探究与扩展"><a href="#最大子矩阵和问题的向量化加速探究与扩展" class="headerlink" title="最大子矩阵和问题的向量化加速探究与扩展"></a><center><strong>最大子矩阵和问题的向量化加速探究与扩展</strong></h1><p>课程名称：汇编与接口</p><p>学生姓名：云中君</p><p>学号：********</p><p>邮件地址：********@zju.edu.cn</p><hr><h2 id="一、探索背景"><a href="#一、探索背景" class="headerlink" title="一、探索背景"></a>一、探索背景</h2><p>​在探索实验开始前，我回顾了过去自己写的很多工程，以从中选择合适的代码进行优化。我尝试着优化了数据库课程中实现的MiniSql和其他课程一些大程，但是发现对于这些大型工程，涉及的代码过于繁杂，且不可避免地使用了很多递归函数，我思索了很久也没有找到合适的加速方法，结果反而使得程序更慢。屡次碰壁的情况下，我发现自己在数据结构基础中，困难模式的程序中有一个是最大子矩阵和的问题，程序相对简洁，利于分析，也涉及到了矩阵相关的运算和循环，在代码结构上，十分契合本次探索的主题，故就该问题进行了向量化加速。</p><p>最大子矩阵和问题的具体描述如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最大子矩阵问题是基于《数据结构与算法分析》教程中“最大子序列和”问题的拓展，它要求我们将一维问题（序列）扩展为二维（矩阵）。更具体地说，我们需要设计 O(N^6)，O(N^4)以及更好的算法，以找到在给定的 N×N 矩阵中其所有元素之和为最大的子矩阵，并给出这个最大的和。</span><br></pre></td></tr></table></figure><p>​在程序设计上，我完成了O(N^6)，O(N^4)以及更优的在线算法，由于O(N^4)和在线算法结构相对类似，所有这里我对前两个复杂度的算法进行了优化。</p><hr><h2 id="二、探索过程"><a href="#二、探索过程" class="headerlink" title="二、探索过程"></a>二、探索过程</h2><h3 id="1-intrinsics选择和文件构成"><a href="#1-intrinsics选择和文件构成" class="headerlink" title="1. intrinsics选择和文件构成"></a>1. intrinsics选择和文件构成</h3><p>​在本实验中，我调用的版本是向量指令是<code>AVX2</code>，具体来说，在程序中包含了头文件<code>#include &lt;immintrin.h&gt;</code>，使用对应的<code>intrinsics</code>来实现向量化加速。</p><p>​包含测试文件的目录结构如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">├── O4_Test.c<span class="comment">//包含了O(N^4)未优化和优化的算法代码</span></span><br><span class="line">├── O6_Test.c<span class="comment">//包含了O(N^6)未优化和优化的算法代码</span></span><br><span class="line">├── output<span class="comment">//Test_case_producer.c输出可以重定向到该文件</span></span><br><span class="line">├── readme.txt</span><br><span class="line">└── Test_case_producer.c<span class="comment">//产生N*N的随机的矩阵</span></span><br></pre></td></tr></table></figure><p>​在编译时，需要加入<code>-mavx2 -mfma</code>等flag，以支持对应的<code>intrinsics</code>。</p><hr><h3 id="2-O-N-6-算法优化"><a href="#2-O-N-6-算法优化" class="headerlink" title="2. O(N^6)算法优化"></a>2. O(N^6)算法优化</h3><h4 id="2-1-原始算法描述"><a href="#2-1-原始算法描述" class="headerlink" title="2.1 原始算法描述"></a>2.1 原始算法描述</h4><p>​该算法的思路是十分简单的循环求解，即对每一个矩阵都进行遍历求和，详细伪代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">float</span> maxsub-matrixsum1&#123;<span class="type">float</span> M[ ][ ]: the matrix, <span class="type">int</span> N: the size of the matrix&#125;</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">float</span> ThisSum, MaxSum := <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> i, j, k, l, m, n;</span><br><span class="line">    <span class="keyword">for</span> i := <span class="number">0</span> to N<span class="number">-1</span>&#123;</span><br><span class="line">        <span class="keyword">for</span> j := <span class="number">0</span> to N<span class="number">-1</span>&#123;</span><br><span class="line">            <span class="keyword">for</span> k := i to N<span class="number">-1</span> &#123;</span><br><span class="line">                <span class="keyword">for</span> l := j to N<span class="number">-1</span> &#123;</span><br><span class="line">                    <span class="comment">/*find the (i,j) position and (k,l) position*/</span></span><br><span class="line">                    ThisSum := <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">for</span> m := i to k &#123;</span><br><span class="line">                        <span class="keyword">for</span> n := j to l &#123;</span><br><span class="line">                        ThisSum += M[m][n];</span><br><span class="line">                    &#125;<span class="comment">/*add from (i,j) to (k,l) */</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> ThisSum &gt; MaxSum then MaxSum := ThisSum;</span><br><span class="line">                <span class="comment">/* update the MaxSum*/</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> MaxSum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-依赖关系分析和向量化尝试"><a href="#2-2-依赖关系分析和向量化尝试" class="headerlink" title="2.2 依赖关系分析和向量化尝试"></a>2.2 依赖关系分析和向量化尝试</h4><p>​正是由于6层循环的嵌套，使得整体程序的效率十分低，复杂度也高达O(N^6)。很自然地，我们可以尝试使用向量化的方式，来对该算法进行加速。</p><p>​首先我们分析代码的结构，在6层循环当中，我们从内而外看，先进行简化，可以看到其最核心的加法操作可以抽象为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt;= m; i++ )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j = <span class="number">0</span>; j &lt;= n; j++ )</span><br><span class="line">    &#123;</span><br><span class="line">        T = T + M[i][j];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​分析其依赖关系，可以看到在循环内，大致有如下图的几种数据依赖：</p><img src="image-20221220233618978.png" alt="image-20221220233618978" style="zoom:50%;" /><p>​因为T(即暂时存当前操作矩阵和的遍量<code>ThisSum</code>)这一跨循环的共有变量存在，在执行过程中数据之间存在了很大的依赖性，其中也存在真实依赖(<code>RAW</code>)，使得向量化难以继续。</p><p>​但是由于T的最终目的是运算当前子矩阵的元素和，具体执行的手段其实可以变化，我们只需要在保证结果正确的前提下，尽可能实现向量化即可。我们可以通过重命名的技术，消除处理RAW之外的反相关和输出相关；对于真相关，我们完全可以分别计算上图中S1、S2语句中的T，只需要在最后将这两个值相加即可，即使未能消除的循环间的真相关，也不会影响程序执行。</p><p>​基于这一思路，我们可以利用向量化的方法，对内层循环的加法进行并行化。我们可以将原先的T分成8个32位<code>float</code>变量，构成一个256位的<code>sum</code>向量；而对于每一行，我们一次<code>load</code> 8个变量到<code>value</code>向量，分别让其与<code>sum</code>向量进行打包相加，从而使并行化成为可能。在最后，我们只需一次性将<code>sum</code>向量导出到数组中，并进行相加，即可得到当前子矩阵的和，这样就实现了简单的向量化并行，具体算法如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Matrix Add--O6_revise1</span></span><br><span class="line"><span class="type">float</span> ThisSum = <span class="number">0</span>;<span class="comment">//reinitialize the temporary sum</span></span><br><span class="line"><span class="type">float</span> Sum[<span class="number">8</span>]=&#123;<span class="number">0</span>,&#125;;</span><br><span class="line">__m256 value;</span><br><span class="line">__m256 sum = _mm256_set1_ps(<span class="number">0</span>);</span><br><span class="line">sum = _mm256_set1_ps(<span class="number">0</span>);</span><br><span class="line"><span class="keyword">for</span>( i = <span class="number">0</span>; i &lt;= r; i++ )</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; ROUNDDOWN(c,<span class="number">8</span>); j+=<span class="number">8</span> )</span><br><span class="line">    &#123;</span><br><span class="line">        value = _mm256_loadu_ps(&amp;M[i+sr][j+sc]);</span><br><span class="line">        sum = _mm256_add_ps(sum, value);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(; j &lt;= c; j++)</span><br><span class="line">        ThisSum += M[i+sr][j+sc];</span><br><span class="line">&#125;<span class="comment">//add from (i,j) to (k,l) by separately incrementing m,n</span></span><br><span class="line">_mm256_storeu_ps(Sum, sum);</span><br><span class="line">ThisSum += Sum[<span class="number">0</span>]+Sum[<span class="number">1</span>]+Sum[<span class="number">2</span>]+Sum[<span class="number">3</span>]+Sum[<span class="number">4</span>]+Sum[<span class="number">5</span>]+Sum[<span class="number">6</span>]+Sum[<span class="number">7</span>];</span><br><span class="line"><span class="keyword">if</span>( ThisSum &gt; MaxSum )</span><br><span class="line">    MaxSum = ThisSum;<span class="comment">//updating the MaxSum if the current sum is larger</span></span><br></pre></td></tr></table></figure><p>​这样的优化仅仅在内层循环，但是性能优化也提升为原来的3倍多，我也尝试了进一步展开外层循环，以进一步地并行化。但是仔细分析，发现很难再减少跨loop导致的加法次数，而向量化指令由于操作数的有限，并不能很好的发挥作用，在处理外层循环时，使用多线程编程可能会是处理比较复杂操作的好的选择。不过展开后仍然发现速度有轻微的提升，并不明显，推测是展开后缓存等效率上，可能会在某些情况下有所优化，但是也无从验证。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//unrolling the loop, makes little change... </span></span><br><span class="line"><span class="keyword">for</span>( i= <span class="number">0</span>; i &lt; ROUNDDOWN(r,<span class="number">2</span>); i+=<span class="number">2</span> )</span><br><span class="line">&#123;</span><br><span class="line"><span class="keyword">for</span>( j = <span class="number">0</span>; j &lt; ROUNDDOWN(c,<span class="number">8</span>); j+=<span class="number">8</span> )</span><br><span class="line">&#123;</span><br><span class="line">value1 = _mm256_loadu_ps(&amp;M[i+sr][j+sc]);</span><br><span class="line">value2 = _mm256_loadu_ps(&amp;M[i+<span class="number">1</span>+sr][j+sc]);</span><br><span class="line">            </span><br><span class="line">sum = _mm256_add_ps(sum, _mm256_add_ps(value1, value2));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(; j &lt;= c; j++)</span><br><span class="line">&#123;</span><br><span class="line">ThisSum += M[i+sr][j+sc];</span><br><span class="line">ThisSum += M[i+<span class="number">1</span>+sr][j+sc];</span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="comment">//add from (i,j) to (k,l) by separately incrementing m,n</span></span><br></pre></td></tr></table></figure><hr><h3 id="3-O-N-4-算法优化"><a href="#3-O-N-4-算法优化" class="headerlink" title="3. O(N^4)算法优化"></a>3. O(N^4)算法优化</h3><p>​对于前面的O(N^6)的算法而言，由于循环有6层，而内部仅有一个加法操作，可向量化的空间并不多，而且算法时间复杂度过高，在这个情况下，优化算法比起向量化并行而言，效益是更高的。所有我进一步尝试，在优化算法后，是否也可以进行进一步的向量化加速。</p><h4 id="3-1-原始算法描述"><a href="#3-1-原始算法描述" class="headerlink" title="3.1 原始算法描述"></a>3.1 原始算法描述</h4><p>​下面是O(N^4)的算法，基本思路为将二维压缩到一维，对于矩阵确定的两行，我们可以获取这两行之间每一列的元素和，存储在数组T中，则T中任意的连续元素和，即为对应的一个子矩阵的元素和。在这个算法下，确定两行需要N^2；而每次更新T的数组需要N，并列地获得所有连续元素和需要N^2，所以总算法复杂度为O(N^4)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> maxsub-matrixsum1&#123;<span class="type">int</span> M[ ][ ]: the matrix, <span class="type">int</span> N: the size of the matrix&#125;</span><br><span class="line">&#123;</span><br><span class="line"><span class="type">int</span> ThisSum, MaxSum := <span class="number">0</span>, T[N]; </span><br><span class="line">    <span class="comment">/* T[N]: the temporary space to store the sum from M[i][k] to M[j][k] */</span></span><br><span class="line"><span class="type">int</span> i, j, k, l;</span><br><span class="line"><span class="keyword">for</span> i := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line"><span class="keyword">for</span> j := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line">T[j] := <span class="number">0</span>;</span><br><span class="line">&#125;<span class="comment">/*reinitialize the T[N] corresponding to i*/</span></span><br><span class="line"><span class="keyword">for</span> j := i to N<span class="number">-1</span> &#123;</span><br><span class="line"><span class="keyword">for</span> k := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line">T[k] += M[j][k];</span><br><span class="line">&#125;<span class="comment">/*T[k] = M[i][k]+M[i+1][k]+...+M[j][k]*/</span></span><br><span class="line"><span class="keyword">for</span> k := <span class="number">0</span> to N<span class="number">-1</span> &#123;</span><br><span class="line">ThisSum := <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> l := k to N<span class="number">-1</span> &#123;</span><br><span class="line">ThisSum += T[l]; <span class="comment">/*similar to the sub-sequence problem*/</span></span><br><span class="line"><span class="keyword">if</span> ThisSum &gt; MaxSum then MaxSum := ThisSum;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> MaxSum;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-2-向量化加速尝试"><a href="#3-2-向量化加速尝试" class="headerlink" title="3.2 向量化加速尝试"></a>3.2 向量化加速尝试</h4><p>​有了前面优化的实践后，我对向量化指令的熟悉程度和使用思路有了更熟练的掌握。与前面同样地，对于过多层嵌套的循环，我们也可以先抽取出内层的细节，来尝试进行向量化加速。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; N; k++ )<span class="comment">//Each time we only need to add the new row to the array T</span></span><br><span class="line">&#123;</span><br><span class="line">    T[k] += M[j][k];<span class="comment">//T[k] = M[i][k]+M[i+1][k]+...+M[j][k]</span></span><br><span class="line">&#125;<span class="comment">//O(N)</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; N; k++)</span><br><span class="line">&#123;</span><br><span class="line">ThisSum = <span class="number">0</span>;<span class="comment">//reinitialize ThisSum</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> l = k; l &lt; N; l++ )</span><br><span class="line">&#123;</span><br><span class="line">        ThisSum += T[l];</span><br><span class="line">        <span class="keyword">if</span>( ThisSum &gt; MaxSum )<span class="comment">//Find the max subsequence sum. </span></span><br><span class="line">            MaxSum = ThisSum;</span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="comment">//O(N^2)</span></span><br></pre></td></tr></table></figure><p>​首先，对于前面O(N)的更新过程，有了前面的基础，可以很快速地完成加速，实现8次相加的并行。此处T[k]之间也没有任何依赖，所有很自然地，只需要<code>load</code>完成后，并行地利用向量进行加法运算即可。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>( k = <span class="number">0</span>; k &lt; ROUNDDOWN(N,<span class="number">8</span>); k+=<span class="number">8</span> )</span><br><span class="line">&#123;</span><br><span class="line">    value1 = _mm256_loadu_ps(&amp;M[j][k]);</span><br><span class="line">    value2 = _mm256_loadu_ps(&amp;T[k]);</span><br><span class="line">    value2 = _mm256_add_ps(value1, value2);</span><br><span class="line">    _mm256_storeu_ps(&amp;T[k], value2);<span class="comment">//T[k] = M[i][k]+M[i+1][k]+...+M[j][k]</span></span><br><span class="line">&#125;<span class="comment">//O(N)</span></span><br><span class="line"><span class="keyword">for</span>(; k &lt; N; k++)</span><br><span class="line">    T[k] += M[j][k];</span><br></pre></td></tr></table></figure><p>​但是这一处的优化，反映在实际程序运行时间上，却是微不足道的。回顾此前算法课程对时间复杂度的分析，不难发现，这一算法费时间的主要部分其实是下面的O(N^2)二层循环部分，与这一部分相比，前面的O(N)部分时间其实可以忽略不计，所以优化了前面部分，才没有很明显的变化。</p><h4 id="3-3-条件判断的处理"><a href="#3-3-条件判断的处理" class="headerlink" title="3.3 条件判断的处理"></a>3.3 条件判断的处理</h4><p>​所以，对于全局的优化，需要重点关注对二层循环的优化。首先注意到，这是一个带条件的循环，每一次，我们需要比较<code>ThisSum</code>和<code>MaxSum</code>的值，来确定是否需要更新最大和。这一点很大程度上阻碍了我们直接使用指令进行向量化的尝试。</p><p>​为了解决条件判断的问题，我们可以尝试从几个思路进行考虑：</p><ol><li>按照上课提到的方法，修改我们程序表达，消除条件判断；</li><li>调整算法的实现，规避条件判断；</li></ol><p>​对于第一个思路，如果直接消除条件判断，我们不难想到的一种直观的方法是，把条件判断作为bool值这些形式，参与到具体的计算。对于此处的条件判断，我们可以尝试改写为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">int</span> k = <span class="number">0</span>; k &lt; N; k++)</span><br><span class="line">&#123;</span><br><span class="line">ThisSum = <span class="number">0</span>;<span class="comment">//reinitialize ThisSum</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> l = k; l &lt; N; l++ )</span><br><span class="line">&#123;</span><br><span class="line">        ThisSum += T[l];</span><br><span class="line">        <span class="type">int</span> b = ThisSum &gt; MaxSum;</span><br><span class="line">        MaxSum = ThisSum * b + MaxSum * (<span class="number">1</span>-b); <span class="comment">//1. involve multiply operation!</span></span><br><span class="line">        MaxSum = ThisSum &amp; b | MaxSum &amp; ~b; <span class="comment">//2. then b should be sign extended</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;<span class="comment">//O(N^2)</span></span><br></pre></td></tr></table></figure><p>​第一种形式是最自然地想法，但是注意到我们引入了乘法，而乘法运算，我们在体系结构、计算机组成课程中都了解过，需要较多的时钟周期来完成，显然为了这样简单的操作，是得不偿失的。所以我们选择第二种，即使用<code>bitwise</code>的与&#x2F;或操作来完成。</p><p>​但是在依赖关系上，循环内层中，<code>ThisSum</code>、b变量(暂时存储比较结果)存在真依赖，而b的真依赖在循环之间是无关的，每个<code>ThisSum</code>和<code>MaxSum</code>对应一个唯一的b值，不会影响具体的操作。但是对于<code>ThisSum</code>而言，有条件比较存在，这一跨循环的依赖是难以消除的。因为对于每一次<code>MaxSum</code>的更新，都唯一决定于这一层循环中<code>ThisSum</code>的值，也就是<code>ThisSum</code>的值具有<strong>“记录”</strong>意义，每次修改得到的都对应最终某个子矩阵的和。所以我们不能像之前的加速方法那样对<code>ThisSum</code>进行分道，来破坏循环间的依赖。</p><img src="image-20221221201513712.png" alt="image-20221221201513712" style="zoom: 50%;" /><p>​但是从对O(N^6)算法的加速的经验上看，我们是不是也可以人为地处理<code>MaxSum</code>这一值，来破坏这一依赖关系，也就是让每次<code>ThisSum</code>在循环间互不相关，不会存在累加的效果。这一处的修改让人摸不着头脑，试图通过-O3查看汇编指令，让编译器给一些提示，但是发现编译器在此处并不采用向量化，只是简单的循环操作，没有采用并行。对此我思考了很久，似乎必须对代码进行重构（类似于课上讲的调换顺序的方法）才可以解决这一优化的瓶颈。</p><h4 id="3-4-向量化遇到的瓶颈及尝试"><a href="#3-4-向量化遇到的瓶颈及尝试" class="headerlink" title="3.4 向量化遇到的瓶颈及尝试"></a>3.4 向量化遇到的瓶颈及尝试</h4><p>​对此我思考了两种方法，在不改变原有代码含义的基础上，通过算法的表述的改进，来试图实现优化。</p><h5 id="3-4-1-使用矩阵操作来解决依赖"><a href="#3-4-1-使用矩阵操作来解决依赖" class="headerlink" title="3.4.1 使用矩阵操作来解决依赖"></a>3.4.1 使用矩阵操作来解决依赖</h5><p>​展开循环，仔细分析<code>ThisSum</code>的所有可能值，我们可以发现它是由下面这些值构成：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">数字n：表示T[n]，以N=<span class="number">4</span>为例</span><br><span class="line"></span><br><span class="line">ThisSum:</span><br><span class="line"><span class="number">1</span> <span class="number">1</span>+<span class="number">2</span> <span class="number">1</span>+<span class="number">2</span>+<span class="number">3</span> <span class="number">1</span>+<span class="number">2</span>+<span class="number">3</span>+<span class="number">4</span></span><br><span class="line"><span class="number">2</span> <span class="number">2</span>+<span class="number">3</span> <span class="number">2</span>+<span class="number">3</span>+<span class="number">4</span></span><br><span class="line"><span class="number">3</span> <span class="number">3</span>+<span class="number">4</span> </span><br><span class="line"><span class="number">4</span></span><br></pre></td></tr></table></figure><p>​我们可以看到，对于所有<code>ThisSum</code>的可能值，可以表示为一个矩阵，这个矩阵的所有元素的值的最大值，与<code>MaxSum</code>的值进行比较，即可获得最终的最大值。观察这个矩阵的特性，我们不难发现，它可以表示为：<br><img src="gs.png"/><br>​这样就包含了我们前面列举的所有<code>ThisSum</code>的情况，也就是我们只需要比较结果矩阵的元素获取最大值即可，也就打破原来存在的依赖。这是我最开始想到的解决方案，但是很明显这里引入了乘法，但是因为在最开始探索时看了很多快速矩阵乘法的优化方法，包括看到过一个论文的报道<a href="https://www.nature.com/articles/s41586-022-05172-4">Discovering faster matrix multiplication algorithms with reinforcement learning | Nature</a>，我盲目地估计了矩阵乘法的速度，参考资料实现了简单的优化后的矩阵乘法算法后，经过测试后，发现还是得不偿失的，这也提醒我在开始优化前，需要合理地评估代价。</p><p>​下面是参考<a href="https://www.leiphone.com/category/yanxishe/Puevv3ZWxn0heoEv.html">OpenBLAS项目与矩阵乘法优化</a>实现的矩阵乘法（使用GEMM优化），主要的逻辑也就是在大矩阵进行乘法时，进行8*8的分块，每次对这一分块进行并行的乘法运算，以加速矩阵乘法，但是结果比优化前慢，说明引入乘法是很不明智的，也是我探索过程中踩过的一个坑。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//8x8 multiplication with AVX2 speeding up(element of the whole mult with GEMM)</span></span><br><span class="line"><span class="type">void</span> <span class="title function_">Mult_8x8</span><span class="params">(<span class="type">int</span> r, <span class="type">int</span> c, <span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C)</span> &#123;</span><br><span class="line">__m256 o[<span class="number">8</span>], a[<span class="number">8</span>], b;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i =<span class="number">0</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">o[i] = _mm256_setzero_ps();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">float</span> *B_row = B;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; r; i++) &#123;</span><br><span class="line"></span><br><span class="line">a[<span class="number">0</span>] = _mm256_set1_ps(A[i]);</span><br><span class="line">a[<span class="number">1</span>] = _mm256_set1_ps(A[c+i]);</span><br><span class="line">a[<span class="number">2</span>] = _mm256_set1_ps(A[<span class="number">2</span>*c+i]);</span><br><span class="line">a[<span class="number">3</span>] = _mm256_set1_ps(A[<span class="number">3</span>*c+i]);</span><br><span class="line">a[<span class="number">4</span>] = _mm256_set1_ps(A[<span class="number">4</span>*c+i]);</span><br><span class="line">a[<span class="number">5</span>] = _mm256_set1_ps(A[<span class="number">5</span>*c+i]);</span><br><span class="line">a[<span class="number">6</span>] = _mm256_set1_ps(A[<span class="number">6</span>*c+i]);</span><br><span class="line">a[<span class="number">7</span>] = _mm256_set1_ps(A[<span class="number">7</span>*c+i]);</span><br><span class="line"></span><br><span class="line">b = _mm256_loadu_ps(B_row);</span><br><span class="line"></span><br><span class="line">o[<span class="number">0</span>] = _mm256_fmadd_ps(a[<span class="number">0</span>], b, o[<span class="number">0</span>]);</span><br><span class="line">o[<span class="number">1</span>] = _mm256_fmadd_ps(a[<span class="number">1</span>], b, o[<span class="number">1</span>]);</span><br><span class="line">o[<span class="number">2</span>] = _mm256_fmadd_ps(a[<span class="number">2</span>], b, o[<span class="number">2</span>]);</span><br><span class="line">o[<span class="number">3</span>] = _mm256_fmadd_ps(a[<span class="number">3</span>], b, o[<span class="number">3</span>]);</span><br><span class="line">o[<span class="number">4</span>] = _mm256_fmadd_ps(a[<span class="number">4</span>], b, o[<span class="number">4</span>]);</span><br><span class="line">o[<span class="number">5</span>] = _mm256_fmadd_ps(a[<span class="number">5</span>], b, o[<span class="number">5</span>]);</span><br><span class="line">o[<span class="number">6</span>] = _mm256_fmadd_ps(a[<span class="number">6</span>], b, o[<span class="number">6</span>]);</span><br><span class="line">o[<span class="number">7</span>] = _mm256_fmadd_ps(a[<span class="number">7</span>], b, o[<span class="number">7</span>]);</span><br><span class="line"></span><br><span class="line">b += <span class="number">8</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; <span class="number">8</span>; i++)</span><br><span class="line">&#123;</span><br><span class="line">_mm256_store_ps(C+i*r, o[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">void</span> <span class="title function_">matrix_mult</span><span class="params">(<span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C)</span></span><br><span class="line">&#123;</span><br><span class="line"><span class="type">float</span> *packed_B = (<span class="type">float</span>*)<span class="built_in">malloc</span>(<span class="number">8</span>*N*<span class="keyword">sizeof</span>(<span class="type">float</span>));</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; j += <span class="number">8</span>) &#123;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line"><span class="built_in">memcpy</span>(packed_B+i*<span class="number">8</span>, B+i*N+j, <span class="keyword">sizeof</span>(<span class="type">float</span>)*<span class="number">8</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i += <span class="number">8</span>) &#123;</span><br><span class="line">Mult_8x8(N, N, A+i*N, packed_B, C+i*N+j);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">free</span>(packed_B);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="3-4-2-调换循环顺序来解决依赖"><a href="#3-4-2-调换循环顺序来解决依赖" class="headerlink" title="3.4.2 调换循环顺序来解决依赖"></a>3.4.2 调换循环顺序来解决依赖</h5><p>​虽然上面的算法修改结果并不理想，但是也给了我一些启示。既然上面的矩阵方法引入了矩阵乘法的操作来实现所有<code>ThisSum</code>的计算，则同样地，我们是否可以用其他的方法，来列举得到所有的可能值，从而也就可以相应地获得最终的最大值？这也就是第二种想法的由来。</p><p>​注意到，每一次<code>ThisSum</code>都是从单独的一个T[k]元素开始，逐步的累加，那么其实以不同的T[k]开头的值对应的这一组<code>ThisSum</code>是无关的，也就是说外层循环之间是无关的，相关性来自内层循环。利用这一点，我们可以尝试下面的这一思路，简单起见，我们假设<strong>每个向量包含两个元素</strong>。</p><img src="image-20221221223832919.png" alt="image-20221221223832919" style="zoom: 50%;" /><p>​按照上图的方法，我们把8个元素分为4组，每一组用一个向量表示，再设置一个记录<code>max</code>值的向量，包含两个元素。第一次我们将各个值load到这些向量中，与<code>max</code>中的向量比较，只要是大于对应<code>lane</code>的值，则替换，否则保持不变。此后，每一次我们对各个元素左移一位，如图操作，再与前一次得到的向量进行加减。这样每一个向量可以表示两个T[k]对应的<code>ThisSum</code>最终值，每次加法操作表示一次叠加，也就是上图中0可以表示T[0]，每加一次，就从<code>T[0]+T[1]+...+T[i]</code>变为<code>T[0]+T[1]+...+T[i]+T[i+1]</code>，1则表示T[1]开始的。这样我们就可以并行地操作一个向量中包含多个系列的<code>ThisSum</code>值，从而实现向量化并行。</p><img src="image-20221221225007431.png" alt="image-20221221225007431" style="zoom: 50%;" /><p>具体的算法实现如下，实际一个向量包含8个元素：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(l=<span class="number">0</span>; l&lt;N; l++)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">for</span>(k=<span class="number">0</span>; k&lt;N-ROUNDDOWN(l,<span class="number">8</span>); k+=<span class="number">8</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        value2 = _mm256_loadu_ps(T+k+l);</span><br><span class="line">        value[k/<span class="number">8</span>] = _mm256_add_ps(value2, value[k/<span class="number">8</span>]);</span><br><span class="line">        <span class="comment">//value1 = max[i] &gt; value[i]? 0xFFFF:0</span></span><br><span class="line">        value1 = _mm256_cmp_ps(max, value[k/<span class="number">8</span>], _CMP_GT_OS);</span><br><span class="line">        <span class="comment">//max = max &amp; value</span></span><br><span class="line">        max = _mm256_and_ps(value1, max);</span><br><span class="line">        <span class="comment">//value1 = not(value1) &amp; value</span></span><br><span class="line">        value1 = _mm256_andnot_ps(value1, value[k/<span class="number">8</span>]);</span><br><span class="line">        max = _mm256_or_ps(max, value1);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​实际的效果上有所提升，但是也并没有老师说的10倍以上，但是至少也有所改进。对于这一个双层循环我能想到的方法也只有这两种，当然通过-O3优化过程中可以看到还是有一些地方可以进一步优化，但是精力有限，就暂时优化到这一层面，进一步的优化还是交给编译器。</p><h2 id="三、效果分析"><a href="#三、效果分析" class="headerlink" title="三、效果分析"></a>三、效果分析</h2><h3 id="1-O-N-6-优化效果"><a href="#1-O-N-6-优化效果" class="headerlink" title="1. O(N^6)优化效果"></a>1. O(N^6)优化效果</h3><p>因为size过大对于O(N^6)的算法十分不友好，<strong>在不加<code>-O3</code>的情况下</strong>，会花费过长时间，故此处选择最大为64：</p><table><thead><tr><th align="left">Size</th><th align="center">16*16</th><th align="center">32*32</th><th align="center">50*50</th><th align="center">64*64</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">1.64*10^-3</td><td align="center">9.52*10^-2</td><td align="center">1.31</td><td align="center">5.77</td></tr><tr><td align="left">With SIMD</td><td align="center">1.10*10^-3</td><td align="center">3.46*10^-2</td><td align="center">3.45*10^-1</td><td align="center">1.30</td></tr><tr><td align="left">Scale</td><td align="center">1.49</td><td align="center">2.75</td><td align="center">3.80</td><td align="center">4.44</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221221234824954.png" alt="image-20221221234824954" height=120 /></td><td align="center"><img src="image-20221221234959581.png" alt="image-20221221234959581" height=120 /></td><td align="center"><img src="image-20221221235149017.png" alt="image-20221221235149017" height=120 /></td><td align="center"><img src="image-20221221235321855.png" alt="image-20221221235321855" height=120 /></td></tr></tbody></table><p>使用<code>-O3</code>进一步优化后：</p><table><thead><tr><th align="left">Size</th><th align="center">32*32</th><th align="center">50*50</th><th align="center">64*64</th><th align="center">100*100</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">2.01*10^-2</td><td align="center">2.98*10^-1</td><td align="center">1.31</td><td align="center">19.3</td></tr><tr><td align="left">With SIMD</td><td align="center">9.02*10^-3</td><td align="center">8.52*10^-2</td><td align="center">3.11*10^-1</td><td align="center">3.29</td></tr><tr><td align="left">Scale</td><td align="center">2.23</td><td align="center">3.50</td><td align="center">4.21</td><td align="center">5.87</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221221234115220.png" alt="image-20221221234115220" height=120 /></td><td align="center"><img src="image-20221221234011974.png" alt="image-20221221234011974" height=120 /></td><td align="center"><img src="image-20221221234338654.png" alt="image-20221221234338654" height=120 /></td><td align="center"><img src="image-20221221234526496.png" alt="image-20221221234526496" height=120 /></td></tr></tbody></table><p>​整体的提速效果随着矩阵的大小而提高，一般能<strong>提高3-4倍</strong>左右，但是由于O(N^6)算法时间复杂度随N增长过快，对过大的矩阵还是会需要很长时间。</p><h3 id="2-O-N-4-优化效果"><a href="#2-O-N-4-优化效果" class="headerlink" title="2. O(N^4)优化效果"></a>2. O(N^4)优化效果</h3><p>对于不加<code>-O3</code>的编译情况：</p><table><thead><tr><th align="left">Size</th><th align="center">50*50</th><th align="center">64*64</th><th align="center">100*100</th><th align="center">500*500</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">4.19*10^-3</td><td align="center">1.12*10^-2</td><td align="center">6.89*10^-2</td><td align="center">44.5</td></tr><tr><td align="left">With SIMD</td><td align="center">3.35*10^-3</td><td align="center">9.17*10^-3</td><td align="center">4.44*10^-2</td><td align="center">25</td></tr><tr><td align="left">Scale</td><td align="center">1.25</td><td align="center">1.22</td><td align="center">1.55</td><td align="center">1.78</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221221235909215.png" alt="image-20221221235909215" height=120 /></td><td align="center"><img src="image-20221222000035239.png" alt="image-20221222000035239" height=120 /></td><td align="center"><img src="image-20221222000231723.png" alt="image-20221222000231723" height=120 /></td><td align="center"><img src="image-20221222000840665.png" alt="image-20221222000840665" height=120 /></td></tr></tbody></table><p>加<code>-O3</code>的情况：</p><table><thead><tr><th align="left">Size</th><th align="center">50*50</th><th align="center">64*64</th><th align="center">100*100</th><th align="center">500*500</th></tr></thead><tbody><tr><td align="left">Without SIMD</td><td align="center">6.62*10^-4</td><td align="center">1.89*10^3</td><td align="center">1.25*10^-2</td><td align="center">10.6</td></tr><tr><td align="left">With SIMD</td><td align="center">2.55*10^-4</td><td align="center">6.13*10^-4</td><td align="center">3.31*10^-3</td><td align="center">1.67</td></tr><tr><td align="left">Scale</td><td align="center">2.60</td><td align="center">3.83</td><td align="center">3.78</td><td align="center">6.35</td></tr><tr><td align="left">Picture</td><td align="center"><img src="image-20221222001021886.png" alt="image-20221222001021886" height=120 /></td><td align="center"><img src="image-20221222001138189.png" alt="image-20221222001138189" height=120 /></td><td align="center"><img src="image-20221222001257508.png" alt="image-20221222001257508" height=120 /></td><td align="center"><img src="image-20221222001531361.png" alt="image-20221222001531361" height=120 /></td></tr></tbody></table><p>​可以看到，在不加<code>-O3</code>的情况下，提速其实并不理想，但是通过我的加速方法，再通过编译器的加速，发现效果很显著，甚至在500*500时达到了<strong>6倍多</strong>，说明我的加速方法为编译器提供了更好的加速条件。</p><h2 id="四、心得体会"><a href="#四、心得体会" class="headerlink" title="四、心得体会"></a>四、心得体会</h2><p>​在最开始做这个实验时，我其实有些眼高手低，一开始就挑选很大的工程比如数据库着手，想很快看到10倍以上的提速效果。但是现实是，我其实连课上讲解的向量化方法都没有完全弄清晰，一上来就选择这样困难的程序，无疑是很难实现的。后来我也转而打算分析一些库的向量化加速手段，比如Eigen，Pytorch2.0等等，但还是希望能够动手去实现提速，毕竟“纸上得来终觉浅，绝知此事要躬行”，只有自己动手加速过，才有更深的体会。</p><p>​后来我选择了最大子矩阵和的算法，一开始还担心会不会过于简单，和上课讲的之前同学的双边滤波算法、曼德勃罗集这些听起来高大上的算法相形见绌。但是在实际加速过程当中，我也遇到了很多问题，并没有自己想的那样顺利。虽然最后提速效果还是没能达到10倍以上，但是我还是很满意，通过自己的分析，找到了为我自己代码加速的钥匙，其间也花了很多时间不断思考和尝试，尤其在条件判断的向量化这一点上。通过动手尝试，我虽然遇到了很多问题，但是也看到了有很多上课不曾讲到的细节，这些也是只有真的去尝试，才能有所体会的，是我本次实验很大的一个收获。</p><h2 id="五、经验教训"><a href="#五、经验教训" class="headerlink" title="五、经验教训"></a>五、经验教训</h2><p>​在做这个实验时，我遇到了很多问题，包括指令层面、加速算法层面等等。</p><ol><li>在最初使用AVX2的<code>intrinsics</code>时，比较不熟练。我最开始使用int型存储的矩阵，所以需要用到<code>epi32</code>等后缀，但是在这一点上，由于int型变量存在加法&#x2F;乘法的溢出现象，有时候32位的int体现在乘法时，会只支持<code>epi16</code>的乘法，这样就会造成很多复杂的情况。所以最后我还是改用了浮点数，使用ps的后缀，这样就避免了不一致的问题。同时，在使用<code>load</code>和<code>store</code>时，我遇到过一段代码在不同位置，有些可以运行，有些不能的情况，后来发现是在于这两个指令默认是对齐存储的数据，但是很多情况对应的数据是不对齐存储，所以就造成了这一个问题，只需要使用<code>loadu/storeu</code>即能解决问题。</li><li>在探究有条件判断的加速算法时，我最开始没有很好地估计乘法带来的巨大开销，从而在最开始就选错了优化的方向，结果自然是得不偿失。而在代码优化过程中，我发现有时候很微小的调整反映在代码运行速度上，会产生巨大的影响，比如默写<code>load</code>操作的位置是否是精确无重复的等等，需要很审慎地处理。</li><li>在向量化加速时，同样需要注意结果的准确性，很多时候确实速度是提上来了，但是一旦结果出错，所有加速都是无用的，我碰到很多次因为循环展开计数不是8的倍数或者部分值没有及时归0，而造成的结果不一致的问题，需要着重考虑这一点。</li><li>此外，我也尝试了多线程的编程进行加速，但是在本题的循环中效果很不理想，推测是因为频繁的<code>pthread_create</code>的同时还需要对每个线程的<code>MaxSum</code>的加锁互斥，造成了比较大的开销。</li></ol><h2 id="六、参考文献"><a href="#六、参考文献" class="headerlink" title="六、参考文献"></a>六、参考文献</h2><ol><li><p><a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#expand=3828,301,2553&ig_expand=104,6169,1021,3206,3206,156,1029,849,343,383">Intel® Intrinsics Guide</a></p></li><li><p><a href="https://www.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/intrinsics/intrinsics-for-intel-advanced-vector-extensions/intrinsics-for-compare-operations-1/mm-cmp-ps-mm256-cmp-ps.html">_mm_cmp_ps, _m256_cmp_ps</a></p></li><li><p><a href="https://www.coder.work/article/6502434">simd - 如何选择 AVX 比较谓词变体</a></p></li><li><p><a href="https://www.felixcloutier.com/x86/pcmpgtb:pcmpgtw:pcmpgtd">PCMPGTB&#x2F;PCMPGTW&#x2F;PCMPGTD — Compare Packed Signed Integers for Greater Than </a></p></li><li><p><a href="https://www.leiphone.com/category/yanxishe/Puevv3ZWxn0heoEv.html">OpenBLAS项目与矩阵乘法优化</a></p></li><li><p><a href="https://www.cnblogs.com/wangguchangqing/p/5466301.html">SSE指令集学习：Compiler Intrinsic - Brook_icv</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/94649418">AVX &#x2F; AVX2 指令编程</a></p></li><li><p><a href="https://blog.csdn.net/AAAA202012/article/details/123983364">SIMD指令集分析(C&#x2F;C++)</a></p></li><li><p><a href="https://www.cnblogs.com/zyl910/archive/2012/04/19/avx_cmp_imm8.html">AVX指令集中的32种浮点比较关系详解（NaN、无序、有序等）</a></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> CS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>七律·忽觉秋凉</title>
      <link href="/2022/10/03/poem_2/"/>
      <url>/2022/10/03/poem_2/</url>
      
        <content type="html"><![CDATA[<h2 id="七律·忽觉秋凉"><a href="#七律·忽觉秋凉" class="headerlink" title="七律·忽觉秋凉"></a><center>七律·忽觉秋凉</center></h2><center>计日归期今又近，暑天潇洒去难留。</center><center>结庐山境浮新雨，横笛云林唤别愁。</center><center>一绺金风轻入户，半年心事散成秋。</center><center>凭将凉意问来处，几点残灯上客舟。</center><h2 id="跋"><a href="#跋" class="headerlink" title="跋"></a>跋</h2><p>搬运一些旧作~</p><h2 id="平台同步"><a href="#平台同步" class="headerlink" title="平台同步"></a>平台同步</h2><p>西窗：也无风雨_<br>微信读书：也无风雨<br>微信公众号：凌云漫谈</p>]]></content>
      
      
      <categories>
          
          <category> 诗词 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 律诗 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>行军集</title>
      <link href="/2022/10/02/collection_1/"/>
      <url>/2022/10/02/collection_1/</url>
      
        <content type="html"><![CDATA[<h2 id="•词"><a href="#•词" class="headerlink" title="•词"></a>•词</h2><h3 id="破阵子"><a href="#破阵子" class="headerlink" title="破阵子"></a><center>破阵子</center></h3><p>云邈但凭龙翥，峰危气胜熊罴。骁浪长鲸驱海兽，梦里秋风会畎夷。豪情荡濬池。</p><p>词笔难言澎湃，行军方晓鸿姿。夕照曾经镶赤壁，也映书生羡骠骑。柔乡今日辞。</p><h3 id="浪淘沙令·次韵柳永"><a href="#浪淘沙令·次韵柳永" class="headerlink" title="浪淘沙令·次韵柳永"></a><center>浪淘沙令·次韵柳永</center></h3><p>鱼雁寄征人。装束精神。炎曦论剑置罗裀。浩唱东坡随太白，豪旷浑身。</p><p>南浦泪衫裙。捣练声新。飞蓬何处尽浮尘。应耐尊前空对月，笔断含颦。</p><h3 id="行香子·次韵东坡"><a href="#行香子·次韵东坡" class="headerlink" title="行香子·次韵东坡"></a><center>行香子·次韵东坡</center></h3><p>训勖方终。阳景酣浓。汗如星、何惧途穷。少年肝胆，谁羡桐封。对胡天雪，吹霜角，射轩龙。</p><p>带三尺剑，听古笙钟。赏蔷薇、也爱戎风。又披迷彩，暂出樊笼。作千秋客，邀侠士，斗蹻容。</p><h3 id="水龙吟•有感军训尾声"><a href="#水龙吟•有感军训尾声" class="headerlink" title="水龙吟•有感军训尾声"></a><center>水龙吟•有感军训尾声</center></h3><p>斜阳常引烟波路，桥底金风迟渡。秋蛩声晚，催人铸剑，明朝起舞。好立天穹，空山自在，游蜂如故。叹不平事多，无须回首，懒寻觅、栖鸾处。</p><p>只问人生几度。似梅寒、敢争新露。营中情义，怕逢阙月，难留君驻。落寞关山，霓虹尘肆，后来相顾。记军装笔挺，平生难再，赴当时路。</p><h2 id="•诗"><a href="#•诗" class="headerlink" title="•诗"></a>•诗</h2><h3 id="五律·军训遇雨"><a href="#五律·军训遇雨" class="headerlink" title="五律·军训遇雨"></a><center>五律·军训遇雨</center></h3><center>越地多风雨，霖霪浸甲裳。</center><center>水高渔父喜，云近学鸠狂。</center><center>既得凌霄志，当期烈日长。</center><center>龙门虽好跃，不纳折腰郎。</center><h3 id="七律•军训途中作"><a href="#七律•军训途中作" class="headerlink" title="七律•军训途中作"></a><center>七律•军训途中作</center></h3><center>翡玉盈盈褚褐藏，清秋万里送军忙。</center><center>影遮老树何需护，风曳江离尚自强。</center><center>薰草林间蛩唱响，蜻蜓翼下好乘凉。</center><center>不忧雨打空狼狈，燕颔书生且耀光。</center><h3 id="七律•致教官"><a href="#七律•致教官" class="headerlink" title="七律•致教官"></a><center>七律•致教官</center></h3><center>我本无情沧浪客，敢挥万将自疏狂。</center><center>凝眸秋雨泠风起，笑靥春烟碧柳扬。</center><center>踏雪风花尘不染，称雄逐鹿剑轻藏。</center><center>海潮愿忍鹏腾远，惟寄行云送少郎。</center><h2 id="跋"><a href="#跋" class="headerlink" title="跋"></a>跋</h2><p>随便写的，有些也是为了卷通讯稿。后来发现，好像那些审稿的牛人都不待见我，那我就不去迎合他们了，就写点自己想写的吧。纪念我的军训时光。（搬运旧作ing）</p><h2 id="平台同步"><a href="#平台同步" class="headerlink" title="平台同步"></a>平台同步</h2><p>西窗：也无风雨_<br>微信读书：也无风雨<br>微信公众号：凌云漫谈</p>]]></content>
      
      
      <categories>
          
          <category> 诗词 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 集子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>无题：记《隐入尘烟》</title>
      <link href="/2022/10/01/poem_1/"/>
      <url>/2022/10/01/poem_1/</url>
      
        <content type="html"><![CDATA[<h2 id="无题"><a href="#无题" class="headerlink" title="无题"></a><center>无题</center></h2><center>赶驴垄上共春耕，陋室归来有笑声。</center><center>各自因缘人尽弃，此间极乐苦中生。</center><center>成双喜字折还皱，入水新衣洗不清。</center><center>明灭残光终黯淡，尘烟漫漫葬无名。</center><h2 id="跋"><a href="#跋" class="headerlink" title="跋"></a>跋</h2><p>前些天趁着假期，在图书馆看完了《隐入烟尘》，为之动容，浅浅写了这一首不甚满意的七律（对仗都没到位）。但也不忍再改，怕心情又难平复，谨以此纪念那隐入尘烟的《隐入尘烟》。</p><h2 id="平台同步"><a href="#平台同步" class="headerlink" title="平台同步"></a>平台同步</h2><p>西窗：也无风雨_<br>微信读书：也无风雨<br>微信公众号：凌云漫谈</p>]]></content>
      
      
      <categories>
          
          <category> 诗词 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 律诗 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>写在最前面</title>
      <link href="/2022/10/01/hello_world/"/>
      <url>/2022/10/01/hello_world/</url>
      
        <content type="html"><![CDATA[<p>欢迎来到也无风雨的Blog！这里大概率更新一点诗词（可能会搬运一些之前写的xs），小概率会放几篇CS相关文章（因为本人专业能力有限，只懂些皮毛），偶尔会写点散文&#x2F;议论（大概率不太会有）。</p><h3 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h3><p>ZJU菜菜一枚</p><h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>可能会搬运之后诗友们的集子~（也许吧）</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
